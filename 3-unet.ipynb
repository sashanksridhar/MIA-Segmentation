{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "885941af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.mse_loss(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.mse_loss(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4a2c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 32, kernel_size = 11, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64, kernel_size = 11, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(6,6),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(12544,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,192*192)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c97280b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.DataParallel(Classification())\n",
    "model.load_state_dict(torch.load('./model/cnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4570d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e42c2159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Classification(\n",
       "    (network): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(11, 11), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU()\n",
       "      (4): AvgPool2d(kernel_size=6, stride=6, padding=0)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU()\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU()\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU()\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU()\n",
       "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (15): Flatten(start_dim=1, end_dim=-1)\n",
       "      (16): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (17): ReLU()\n",
       "      (18): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (19): ReLU()\n",
       "      (20): Linear(in_features=512, out_features=36864, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bedaf467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isListEmpty(inList):\n",
    "    if isinstance(inList, list): # Is a list\n",
    "        return all( map(isListEmpty, inList) )\n",
    "    return False # Not a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aff70d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "path = 'data/ACDC/train'\n",
    "\n",
    "for image_path in os.listdir(os.path.join(path, 'images')):\n",
    "    x = np.zeros((64, 64), dtype=\"float32\")\n",
    "    y = np.zeros((64, 64), dtype=\"float32\")\n",
    "\n",
    "    images = cv2.imread(os.path.join(path, 'images', image_path), cv2.IMREAD_GRAYSCALE)\n",
    "#     print(images.size)\n",
    "    images = images/255.0\n",
    "#     print(images)\n",
    "    img = images.reshape(1, 1, images.shape[0], images.shape[1])\n",
    "    \n",
    "    target = cv2.imread(os.path.join(path, 'mask', image_path))\n",
    "                        \n",
    "                        \n",
    "    img = torch.from_numpy(img)\n",
    "\n",
    "    img = img.float()\n",
    "\n",
    "    out = model(img)\n",
    "\n",
    "    out = out.cpu().detach().numpy()\n",
    "    \n",
    "#     print(out)\n",
    "    \n",
    "    where = np.array(np.where(out.reshape(192, 192) > 0.5))\n",
    "#     where = np.array(np.where(out.reshape(192, 192)))\n",
    "\n",
    "    \n",
    "\n",
    "    if isListEmpty(where):\n",
    "        x = cv2.resize(images, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "        y = cv2.resize(target, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "    try:\n",
    "        X_min, Y_min = np.amin(where, axis=1)\n",
    "        X_max, Y_max = np.amax(where, axis=1)\n",
    "    except:\n",
    "        x = cv2.resize(images, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "        y = cv2.resize(target, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "\n",
    "    X_middle = X_min + (X_max - X_min) / 2\n",
    "    Y_middle = Y_min + (Y_max - Y_min) / 2\n",
    "    # Find ROI coordinates\n",
    "#     print(where)\n",
    "    X_top = int(X_middle - 50)\n",
    "    Y_top = int(Y_middle - 50)\n",
    "    X_down = int(X_middle + 50 )\n",
    "    Y_down = int(Y_middle + 50 )\n",
    "    \n",
    "#     print(X_min)\n",
    "#     print(Y_min)\n",
    "#     print(X_max)\n",
    "#     print(Y_max)\n",
    "    \n",
    "#     print(\"****\")\n",
    "    \n",
    "#     print(X_top)\n",
    "#     print(Y_top)\n",
    "#     print(X_down)\n",
    "#     print(Y_down)\n",
    "\n",
    "    if X_top <= 0:\n",
    "        X_down = X_down + (100 - (X_down - X_top)) - X_top\n",
    "        X_top = 0\n",
    "\n",
    "    if Y_top <= 0:\n",
    "        Y_down = Y_down + (100 - (Y_down - Y_top)) - Y_top\n",
    "        Y_top = 0\n",
    "\n",
    "    if X_down > 191:\n",
    "        X_top = X_top + (191 - X_down)\n",
    "        X_down = 191\n",
    "\n",
    "    if Y_down > 191:\n",
    "        Y_top = Y_top + (191- Y_down)\n",
    "        Y_down = 191\n",
    "    images = cv2.imread(os.path.join(path, 'images', image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    x_t = images[X_top:X_down, Y_top:Y_down]\n",
    "    x = cv2.resize(x_t,(64 , 64))\n",
    "\n",
    "    y_t = target[X_top:X_down, Y_top:Y_down]\n",
    "    y = cv2.resize(y_t,(64 , 64), interpolation = cv2.INTERSECT_NONE)\n",
    "    \n",
    "    im = Image.fromarray(x_t)\n",
    "    im.save(os.path.join('data/ACDC/resized/train/images', image_path.split('.')[0]+\".jpg\"))\n",
    "    \n",
    "    im = Image.fromarray(y_t)\n",
    "    im.save(os.path.join('data/ACDC/resized/train/mask', image_path.split('.')[0]+\".jpg\"))\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccca3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "path = 'data/ACDC/test'\n",
    "\n",
    "for image_path in os.listdir(os.path.join(path, 'images')):\n",
    "    x = np.zeros((64, 64), dtype=\"float32\")\n",
    "    y = np.zeros((64, 64), dtype=\"float32\")\n",
    "\n",
    "    images = cv2.imread(os.path.join(path, 'images', image_path), cv2.IMREAD_GRAYSCALE)\n",
    "#     print(images.size)\n",
    "    images = images/255.0\n",
    "#     print(images)\n",
    "    img = images.reshape(1, 1, images.shape[0], images.shape[1])\n",
    "    \n",
    "    target = cv2.imread(os.path.join(path, 'mask', image_path))\n",
    "                        \n",
    "                        \n",
    "    img = torch.from_numpy(img)\n",
    "\n",
    "    img = img.float()\n",
    "\n",
    "    out = model(img)\n",
    "\n",
    "    out = out.cpu().detach().numpy()\n",
    "    \n",
    "#     print(out)\n",
    "    \n",
    "    where = np.array(np.where(out.reshape(192, 192) > 0.5))\n",
    "#     where = np.array(np.where(out.reshape(192, 192)))\n",
    "\n",
    "    \n",
    "\n",
    "    if isListEmpty(where):\n",
    "        x = cv2.resize(images, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "        y = cv2.resize(target, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "    try:\n",
    "        X_min, Y_min = np.amin(where, axis=1)\n",
    "        X_max, Y_max = np.amax(where, axis=1)\n",
    "    except:\n",
    "        x = cv2.resize(images, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "        y = cv2.resize(target, (64, 64), interpolation = cv2.INTERSECT_NONE)\n",
    "\n",
    "    X_middle = X_min + (X_max - X_min) / 2\n",
    "    Y_middle = Y_min + (Y_max - Y_min) / 2\n",
    "    # Find ROI coordinates\n",
    "#     print(where)\n",
    "    X_top = int(X_middle - 50)\n",
    "    Y_top = int(Y_middle - 50)\n",
    "    X_down = int(X_middle + 50 )\n",
    "    Y_down = int(Y_middle + 50 )\n",
    "    \n",
    "#     print(X_min)\n",
    "#     print(Y_min)\n",
    "#     print(X_max)\n",
    "#     print(Y_max)\n",
    "    \n",
    "#     print(\"****\")\n",
    "    \n",
    "#     print(X_top)\n",
    "#     print(Y_top)\n",
    "#     print(X_down)\n",
    "#     print(Y_down)\n",
    "\n",
    "    if X_top <= 0:\n",
    "        X_down = X_down + (100 - (X_down - X_top)) - X_top\n",
    "        X_top = 0\n",
    "\n",
    "    if Y_top <= 0:\n",
    "        Y_down = Y_down + (100 - (Y_down - Y_top)) - Y_top\n",
    "        Y_top = 0\n",
    "\n",
    "    if X_down > 191:\n",
    "        X_top = X_top + (191 - X_down)\n",
    "        X_down = 191\n",
    "\n",
    "    if Y_down > 191:\n",
    "        Y_top = Y_top + (191- Y_down)\n",
    "        Y_down = 191\n",
    "    images = cv2.imread(os.path.join(path, 'images', image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    x_t = images[X_top:X_down, Y_top:Y_down]\n",
    "    x = cv2.resize(x_t,(64 , 64))\n",
    "\n",
    "    y_t = target[X_top:X_down, Y_top:Y_down]\n",
    "    y = cv2.resize(y_t,(64 , 64), interpolation = cv2.INTERSECT_NONE)\n",
    "    \n",
    "    im = Image.fromarray(x_t)\n",
    "    im.save(os.path.join('data/ACDC/resized/test/images', image_path.split('.')[0]+\".jpg\"))\n",
    "    \n",
    "    im = Image.fromarray(y_t)\n",
    "    im.save(os.path.join('data/ACDC/resized/test/mask', image_path.split('.')[0]+\".jpg\"))\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb442b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8845e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820ce867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 06:23:21.809374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 06:23:22.038732: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-06 06:23:23.846528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home2/sashank.sridhar/miniconda3/envs/TripletLoss/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-10.2/lib64:/opt/cudnn-7.6.5.32-cuda-10.2/lib64\n",
      "2023-05-06 06:23:23.846716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home2/sashank.sridhar/miniconda3/envs/TripletLoss/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-10.2/lib64:/opt/cudnn-7.6.5.32-cuda-10.2/lib64\n",
      "2023-05-06 06:23:23.846734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    \"\"\"\n",
    "    The custom data generator class generates and feeds data to\n",
    "    the model dynamically in batches during the training phase.\n",
    "    \n",
    "    This generator generates batched of data for the dataset available @\n",
    "    Find the nuclei in divergent images to advance medical discovery -\n",
    "    https://www.kaggle.com/c/data-science-bowl-2018\n",
    "    \n",
    "    **\n",
    "    tf.keras.utils.Sequence is the root class for \n",
    "    Custom Data Generators.\n",
    "    **\n",
    "    \n",
    "    Args:\n",
    "        image_ids: the ids of the image.\n",
    "        img_path: the full path of the image directory.\n",
    "        batch_size: no. of images to be included in a batch feed. Default is set to 8.\n",
    "        image_size: size of the image. Default is set to 128 as per the data available.\n",
    "        \n",
    "    Ref: https://dzlab.github.io/dltips/en/keras/data-generator/\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, image_ids, img_path, batch_size = 8, image_size = 128):\n",
    "        \n",
    "        self.ids = image_ids\n",
    "        self.path = img_path\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __load__(self, item):\n",
    "        \n",
    "        \"\"\"\n",
    "        loads the specified image.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # the name for parent of parent directory where the image is located and the name of the image are same.\n",
    "        # an example directory breakup is shown below -\n",
    "        # - data-science-bowl-2018/\n",
    "        #      - stage1_train/\n",
    "        #          - abc\n",
    "        #             - image\n",
    "        #                  - abc\n",
    "        #             - mask\n",
    "        full_image_path = os.path.join(self.path, \"images/\", item)\n",
    "\n",
    "#         print(item)\n",
    "        # load the images\n",
    "        image = cv2.imread(full_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#         print(full_image_path)\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        \n",
    "        masked_img = np.zeros((self.image_size, self.image_size, 1))\n",
    "        \n",
    "        # load and prepare the corresponding mask.\n",
    "        \n",
    "        fullPath = os.path.join(self.path, \"mask/\", item)\n",
    "        masked_img = cv2.imread(fullPath, cv2.IMREAD_GRAYSCALE)\n",
    "        masked_img = cv2.resize(masked_img, (self.image_size, self.image_size))\n",
    "#         _masked_img = np.expand_dims(_masked_img, axis = -1)\n",
    "#         masked_img = np.maximum(masked_img, _masked_img)\n",
    "            \n",
    "        # mormalize the mask and the image. \n",
    "        image = image/255.0\n",
    "        masked_img = masked_img/255.0\n",
    "        \n",
    "        return image, masked_img\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns a single batch of data.\n",
    "        \n",
    "        Args:\n",
    "            index: the batch index.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # edge case scenario where there are still some items left\n",
    "        # after segregatings the images into batches of size batch_size.\n",
    "        # the items left out will form one batch at the end.\n",
    "        if(index + 1) * self.batch_size > len(self.ids):\n",
    "            self.batch_size = len(self.ids) - index * self.batch_size\n",
    "        \n",
    "        # group the items into a batch.\n",
    "        batch = self.ids[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        \n",
    "        image = []\n",
    "        mask  = []\n",
    "        \n",
    "        # load the items in the current batch\n",
    "        for item in batch:\n",
    "            img, masked_img = self.__load__(item)\n",
    "            image.append(img)\n",
    "            mask.append(masked_img)\n",
    "        \n",
    "        image = np.array(image)\n",
    "        mask  = np.array(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        optional method to run some logic at the end of each epoch: e.g. reshuffling\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns the number of batches\n",
    "        \"\"\"\n",
    "        return int(np.ceil(len(self.ids)/float(self.batch_size)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a613f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "image_channels = 1\n",
    "image_dir = \"data/ACDC/resized/train/images\"\n",
    "val_dir = \"data/ACDC/resized/test/images\"\n",
    "epochs = 20\n",
    "batch_size = 8\n",
    "\n",
    "# there are a total of 670 items at the train_path directory.\n",
    "# so fixing 600 of data available for training set\n",
    "# 50 for validation set and 20 for test set.\n",
    "# validation_data_size = 50\n",
    "# test_data_size = 20\n",
    "# train_data_size = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41dd56d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "image_ids = os.listdir(image_dir)\n",
    "training_data_ids = image_ids\n",
    "\n",
    "image_ids = os.listdir(val_dir)\n",
    "\n",
    "validation_data_ids = image_ids\n",
    "\n",
    "image_ids = []\n",
    "for i in training_data_ids:\n",
    "    if i != '.ipynb_checkpoints':\n",
    "        image_ids.append(i)\n",
    "training_data_ids = image_ids\n",
    "print('mask' in training_data_ids)\n",
    "\n",
    "image_ids = []\n",
    "for i in validation_data_ids:\n",
    "    if i != '.ipynb_checkpoints':\n",
    "        image_ids.append(i)\n",
    "validation_data_ids = image_ids\n",
    "print('mask' in validation_data_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72839219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Dimension Details: (8, 64, 64) (8, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "temp_data_generator = DataGenerator(image_ids = training_data_ids, \n",
    "                                          img_path = 'data/ACDC/resized/train/', \n",
    "                                          batch_size = batch_size, \n",
    "                                          image_size = image_size)\n",
    "\n",
    "# get one batch of data\n",
    "images, masks = temp_data_generator.__getitem__(0)\n",
    "print(\"Batch Dimension Details:\", images.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801f52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisualizeImageAndMask(image, mask, prediction_img = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Displays the image, mask and the predicted mask\n",
    "    of the input image.\n",
    "    \n",
    "    Args:\n",
    "        image: the original image.\n",
    "        mask: the given mask of the image.\n",
    "        prediction_img: the predicted mask of the image.\n",
    "        \n",
    "    Return:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(hspace = 0.6, wspace = 0.6)\n",
    "    fig.suptitle('Image & Mask(s)', fontsize = 15)\n",
    "    fig.subplots_adjust(top = 1.15)\n",
    "    \n",
    "    ax = fig.add_subplot(1, 3, 1)\n",
    "    ax.imshow(image, cmap = \"gray\")\n",
    "    setTitleAndRemoveTicks(ax, 'Microscopic\\nImage')\n",
    "    \n",
    "    ax = fig.add_subplot(1, 3, 2)\n",
    "    ax.imshow(mask, cmap = \"gray\")\n",
    "    setTitleAndRemoveTicks(ax, 'Original\\nMask')\n",
    "    \n",
    "    if prediction_img is not None:\n",
    "        ax = fig.add_subplot(1, 3, 3)\n",
    "        ax.imshow(np.reshape(prediction_img, (image_size, image_size)), cmap = \"gray\")\n",
    "        setTitleAndRemoveTicks(ax, 'Predicted\\nMask')\n",
    "    \n",
    "def setTitleAndRemoveTicks(axes, title):\n",
    "    \n",
    "    \"\"\"\n",
    "    Sets the sub-plot title and removes the \n",
    "    x & y ticks on the respective axes.\n",
    "    \n",
    "    Args:\n",
    "        axes: the subplot.\n",
    "        title: title of the subplot.\n",
    "        \n",
    "    Return:\n",
    "        None\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # set plot title\n",
    "    axes.title.set_text(title)\n",
    "    \n",
    "    # remove the ticks\n",
    "    axes.set_xticks([])\n",
    "    axes.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02bc33d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60065e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "VisualizeImageAndMask(image = images[1], mask = masks[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65c7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0,1 ])\n",
    "    union = K.sum(y_true, axis=[0,1]) + K.sum(y_pred, axis=[0,1])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    \"\"\"combine DICE and BCE\"\"\"\n",
    "    return 0.01*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ef464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, Cropping2D, Concatenate\n",
    "\n",
    "class UnetUtils():\n",
    "    \n",
    "    \"\"\" \n",
    "    Unet Model design utillities framework.\n",
    "    \n",
    "    This module provides a convenient way to create different layers/blocks\n",
    "    which the UNet network is based upon. It consists of a contracting\n",
    "    path and an expansive path. Both these paths are joined by a bottleneck block.\n",
    "    \n",
    "    The different blocks involved in the design of the network can be referenced @ \n",
    "    U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "    \n",
    "    Source:\n",
    "        https://arxiv.org/pdf/1505.04597\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def contracting_block(self, input_layer, filters, padding, kernel_size = 3):\n",
    "        \n",
    "        \"\"\" \n",
    "        UNet Contracting block\n",
    "        Perform two unpadded convolutions with a specified number of filters and downsample\n",
    "        through max-pooling.\n",
    "        \n",
    "        Args:\n",
    "            input_layer: the input layer on which the current layers should work upon.\n",
    "            filters (int): Number of filters in convolution.\n",
    "            kernel_size (int/tuple): Index of block. Default is 3.\n",
    "            padding (\"valid\" or \"same\"): Default is \"valid\" (no padding involved).\n",
    "            \n",
    "        Return:\n",
    "            Tuple of convolved ``inputs`` after and before downsampling\n",
    "        \"\"\"\n",
    "        \n",
    "        # two 3x3 convolutions (unpadded convolutions), each followed by\n",
    "        # a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2\n",
    "        # for downsampling.\n",
    "        conv = Conv2D(filters = filters, \n",
    "                      kernel_size = kernel_size, \n",
    "                      activation = tf.nn.relu, \n",
    "                      padding = padding)(input_layer)\n",
    "\n",
    "        conv = Conv2D(filters = filters, \n",
    "                      kernel_size = kernel_size, \n",
    "                      activation = tf.nn.relu, \n",
    "                      padding = padding)(conv)\n",
    "\n",
    "        pool = MaxPooling2D(pool_size = 2, \n",
    "                            strides = 2)(conv)\n",
    "\n",
    "        return conv, pool\n",
    "\n",
    "    def bottleneck_block(self, input_layer, filters, padding, kernel_size = 3, strides = 1):\n",
    "        \n",
    "        \"\"\" \n",
    "        UNet bottleneck block\n",
    "        \n",
    "        Performs 2 unpadded convolutions with a specified number of filters.\n",
    "        \n",
    "        Args:\n",
    "            input_layer: the input layer on which the current layers should work upon.\n",
    "            filters (int): Number of filters in convolution.\n",
    "            kernel_size (int/tuple): Index of block. Default is 3.\n",
    "            padding (\"valid\" or \"same\"): Default is \"valid\" (no padding involved).\n",
    "            strides: An integer or tuple/list of 2 integers, specifying the strides \n",
    "                     of the convolution along the height and width. Default is 1.\n",
    "        Return:\n",
    "            The convolved ``inputs``.\n",
    "        \"\"\"\n",
    "        \n",
    "        # two 3x3 convolutions (unpadded convolutions), each followed by\n",
    "        # a rectified linear unit (ReLU)\n",
    "        conv = Conv2D(filters = filters, \n",
    "                      kernel_size = kernel_size, \n",
    "                      padding = padding,\n",
    "                      strides = strides, \n",
    "                      activation = tf.nn.relu)(input_layer)\n",
    "\n",
    "        conv = Conv2D(filters = filters, \n",
    "                      kernel_size = kernel_size, \n",
    "                      padding = padding,\n",
    "                      strides = strides, \n",
    "                      activation = tf.nn.relu)(conv)\n",
    "\n",
    "        return conv\n",
    "\n",
    "    def expansive_block(self, input_layer, skip_conn_layer, filters, padding, kernel_size = 3, strides = 1):\n",
    "        \n",
    "        \"\"\" \n",
    "        UNet expansive (upsample) block.\n",
    "        \n",
    "        Transpose convolution which doubles the spatial dimensions (height and width) \n",
    "        of the incoming feature maps and creates the skip connections with the corresponding \n",
    "        feature maps from the contracting (downsample) path. These skip connections bring the feature maps \n",
    "        from earlier layers helping the network to generate better semantic feature maps.\n",
    "        \n",
    "        Perform two unpadded convolutions with a specified number of filters \n",
    "        and upsamples the incomming feature map.\n",
    "        \n",
    "        Args:\n",
    "            input_layer: the input layer on which the current layers should work upon.\n",
    "            skip_connection: The feature map from the contracting (downsample) path from which the \n",
    "                             skip connection has to be created.\n",
    "            filters (int): Number of filters in convolution.\n",
    "            kernel_size (int/tuple): Index of block. Default is 3.\n",
    "            padding (\"valid\" or \"same\"): Default is \"valid\" (no padding involved).\n",
    "            strides: An integer or tuple/list of 2 integers, specifying the strides \n",
    "                     of the convolution along the height and width. Default is 1.\n",
    "                     \n",
    "        Return:\n",
    "            The upsampled feature map.\n",
    "        \"\"\"\n",
    "        \n",
    "        # up sample the feature map using transpose convolution operations.\n",
    "        transConv = Conv2DTranspose(filters = filters, \n",
    "                                    kernel_size = (2, 2),\n",
    "                                    strides = 2, \n",
    "                                    padding = padding)(input_layer)\n",
    "        \n",
    "        # crop the source feature map so that the skip connection can be established.\n",
    "        # the original paper implemented unpadded convolutions. So cropping is necessary \n",
    "        # due to the loss of border pixels in every convolution.\n",
    "        # establish the skip connections.\n",
    "        if padding == \"valid\":\n",
    "            cropped = self.crop_tensor(skip_conn_layer, transConv)\n",
    "            concat = Concatenate()([transConv, cropped])\n",
    "        else:\n",
    "            concat = Concatenate()([transConv, skip_conn_layer])\n",
    "        \n",
    "        # two 3x3 convolutions, each followed by a ReLU\n",
    "        up_conv = Conv2D(filters = filters, \n",
    "                         kernel_size = kernel_size, \n",
    "                         padding = padding, \n",
    "                         activation = tf.nn.relu)(concat)\n",
    "\n",
    "        up_conv = Conv2D(filters = filters, \n",
    "                         kernel_size = kernel_size, \n",
    "                         padding = padding, \n",
    "                         activation = tf.nn.relu)(up_conv)\n",
    "\n",
    "        return up_conv\n",
    "    \n",
    "    def crop_tensor(self, source_tensor, target_tensor):\n",
    "        \n",
    "        \"\"\"\n",
    "        Center crops the source tensor to the size of the target tensor size.\n",
    "        The tensor shape format is [batchsize, height, width, channels]\n",
    "        \n",
    "        Args:\n",
    "            source_tensor: the tensor that is to be cropped.\n",
    "            target_tensor: the tensor to whose size the \n",
    "                           source needs to be cropped to.\n",
    "                           \n",
    "        Return:\n",
    "            the cropped version of the source tensor.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        target_tensor_size = target_tensor.shape[2]\n",
    "        source_tensor_size = source_tensor.shape[2]\n",
    "        \n",
    "        # calculate the delta to ensure correct cropping.\n",
    "        delta = source_tensor_size - target_tensor_size\n",
    "        delta = delta // 2\n",
    "        \n",
    "        cropped_source = source_tensor[:, delta:source_tensor_size - delta, delta:source_tensor_size - delta, :]\n",
    "        \n",
    "        return cropped_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db3e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "UnetUtils = UnetUtils()\n",
    "\n",
    "class Unet():\n",
    "    \n",
    "    \"\"\" \n",
    "    Unet Model design.\n",
    "    \n",
    "    This module consumes the Unet utilities framework moule and designs the Unet network.\n",
    "    It consists of a contracting path and an expansive path. Both these paths are joined \n",
    "    by a bottleneck block.\n",
    "    \n",
    "    The different blocks involved in the design of the network can be referenced @ \n",
    "    U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "    \n",
    "    Source:\n",
    "        https://arxiv.org/pdf/1505.04597\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape = (572, 572, 1), filters = [64, 128, 256, 512, 1024], padding = \"valid\"):\n",
    "        \"\"\"\n",
    "        \n",
    "        Initialize the Unet framework and the model parameters - input_shape, \n",
    "        filters and padding type. \n",
    "        \n",
    "        Args:\n",
    "            input_shape: The shape of the input to the network. A tuple comprising of (img_height, img_width, channels).\n",
    "                         Original paper implementation is (572, 572, 1).\n",
    "            filters: a collection of filters denoting the number of components to be used at each blocks along the \n",
    "                     contracting and expansive paths. The original paper implementation for number of filters along the \n",
    "                     contracting and expansive paths are [64, 128, 256, 512, 1024].\n",
    "            padding: the padding type to be used during the convolution step. The original paper used unpadded convolutions \n",
    "                     which is of type \"valid\".\n",
    "         \n",
    "        **Remarks: The default values are as per the implementation in the original paper @ https://arxiv.org/pdf/1505.04597\n",
    "        \n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        self.filters = filters\n",
    "        self.padding = padding\n",
    "    \n",
    "    def Build_UNetwork(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Builds the Unet Model network.\n",
    "        \n",
    "        Args:\n",
    "            None\n",
    "         \n",
    "        Return:\n",
    "            The Unet Model.\n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        UnetInput = Input(self.input_shape)\n",
    "        \n",
    "        # the contracting path. \n",
    "        # the last item in the filetrs collection points to the number of filters in the bottleneck block.\n",
    "        conv1, pool1 = UnetUtils.contracting_block(input_layer = UnetInput, filters = self.filters[0], padding = self.padding)\n",
    "        conv2, pool2 = UnetUtils.contracting_block(input_layer = pool1, filters = self.filters[1], padding = self.padding)\n",
    "        conv3, pool3 = UnetUtils.contracting_block(input_layer = pool2, filters = self.filters[2], padding = self.padding)\n",
    "        conv4, pool4 = UnetUtils.contracting_block(input_layer = pool3, filters = self.filters[3], padding = self.padding)\n",
    "        \n",
    "        # bottleneck block connecting the contracting and the expansive paths.\n",
    "        bottleNeck = UnetUtils.bottleneck_block(pool4, filters = self.filters[4], padding = self.padding)\n",
    "\n",
    "        # the expansive path.\n",
    "        upConv1 = UnetUtils.expansive_block(bottleNeck, conv4, filters = self.filters[3], padding = self.padding) \n",
    "        upConv2 = UnetUtils.expansive_block(upConv1, conv3, filters = self.filters[2], padding = self.padding) \n",
    "        upConv3 = UnetUtils.expansive_block(upConv2, conv2, filters = self.filters[1], padding = self.padding) \n",
    "        upConv4 = UnetUtils.expansive_block(upConv3, conv1, filters = self.filters[0], padding = self.padding) \n",
    "\n",
    "        UnetOutput = Conv2D(1, (1, 1), padding = self.padding, activation = tf.math.sigmoid)(upConv4)\n",
    "        \n",
    "        model = Model(UnetInput, UnetOutput, name = \"UNet\")\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def CompileAndSummarizeModel(self, model, optimizer = \"adam\", loss = \"binary_crossentropy\"):\n",
    "        \n",
    "        \"\"\"\n",
    "        Compiles and displays the model summary of the Unet model.\n",
    "        \n",
    "        Args:\n",
    "            model: The Unet model.\n",
    "            optimizer: model optimizer. Default is the adam optimizer.\n",
    "            loss: the loss function. Default is the binary cross entropy loss.\n",
    "            \n",
    "        Return:\n",
    "            None\n",
    "        \n",
    "        \"\"\"\n",
    "        model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=\"binary_crossentropy\", metrics=[dice_coef])\n",
    "        model.summary()\n",
    "        \n",
    "    def plotModel(self, model, to_file = 'unet.png', show_shapes = True, dpi = 96):\n",
    "        \n",
    "        \"\"\"\n",
    "        Saves the Unet model to a file.\n",
    "        \n",
    "        Args:\n",
    "            model: the Unet model. \n",
    "            to_file: the file name to save the model. Default name - 'unet.png'.\n",
    "            show_shapes: whether to display shape information. Default = True.\n",
    "            dpi: dots per inch. Default value is 96.\n",
    "            \n",
    "        Return:\n",
    "            None\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        tf.keras.utils.plot_model(model, to_file = to_file, show_shapes = show_shapes, dpi = dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d94fb857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 06:23:28.929996: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home2/sashank.sridhar/miniconda3/envs/TripletLoss/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/cuda-10.2/lib64:/opt/cudnn-7.6.5.32-cuda-10.2/lib64\n",
      "2023-05-06 06:23:28.930037: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-05-06 06:23:28.930465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "unet = Unet(input_shape = (64, 64, image_channels), \n",
    "            filters = [16, 32, 64, 128, 256], \n",
    "            padding = \"same\")\n",
    "\n",
    "# call the build netowrk API to build the network.\n",
    "model = unet.Build_UNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "197fee7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 16)   160         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 64, 16)   2320        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 32, 16)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 32)   4640        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 32)   9248        ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 64)   18496       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 8, 8, 128)    73856       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 8, 8, 128)    147584      ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 128)   0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 4, 4, 256)    295168      ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 4, 4, 256)    590080      ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 8, 8, 128)   131200      ['conv2d_9[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 256)    0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 128)    295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 128)    147584      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 16, 16, 64)  32832       ['conv2d_11[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 16, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 64)   73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 64)   36928       ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 32, 32, 32)  8224        ['conv2d_13[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 32, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 32, 32)   18464       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 32, 32)   9248        ['conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 64, 64, 16)  2064        ['conv2d_15[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 64, 32)   0           ['conv2d_transpose_3[0][0]',     \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 64, 64, 16)   4624        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 64, 64, 16)   2320        ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 64, 1)    17          ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,817\n",
      "Trainable params: 1,940,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile & summarize the model\n",
    "if model is not None:\n",
    "    unet.CompileAndSummarizeModel(model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4804f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msashank-ssridhar\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/ssd_scratch/cvit/sashank.sridhar/project/wandb/run-20230506_062335-zxoypldg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sashank-ssridhar/MIA/runs/zxoypldg' target=\"_blank\">Unet</a></strong> to <a href='https://wandb.ai/sashank-ssridhar/MIA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sashank-ssridhar/MIA' target=\"_blank\">https://wandb.ai/sashank-ssridhar/MIA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sashank-ssridhar/MIA/runs/zxoypldg' target=\"_blank\">https://wandb.ai/sashank-ssridhar/MIA/runs/zxoypldg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sashank-ssridhar/MIA/runs/zxoypldg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1475c9074910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(name='Unet', \n",
    "           project='MIA',\n",
    "           notes='Unet Segmentation', \n",
    "           tags=['ACDC dataset', 'Train Run'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5478e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(image_ids = training_data_ids, \n",
    "                                img_path = 'data/ACDC/resized/train', \n",
    "                                image_size = image_size, \n",
    "                                batch_size = batch_size)\n",
    "\n",
    "valid_gen = DataGenerator(image_ids = validation_data_ids, \n",
    "                                img_path = 'data/ACDC/resized/test', \n",
    "                                image_size = image_size, \n",
    "                                batch_size = batch_size)\n",
    "\n",
    "# test_gen = DataGenerator(image_ids = testing_data_ids, \n",
    "#                                img_path = image_dir, \n",
    "#                                image_size = image_size, \n",
    "#                                batch_size = batch_size)\n",
    "\n",
    "train_steps = len(training_data_ids)//batch_size\n",
    "valid_steps = len(validation_data_ids)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "797760e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a9b7183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "155/155 [==============================] - 12s 70ms/step - loss: 0.5953 - dice_coef: 0.2263 - val_loss: 0.4468 - val_dice_coef: 0.2464\n",
      "Epoch 2/250\n",
      "155/155 [==============================] - 9s 60ms/step - loss: 0.3781 - dice_coef: 0.3160 - val_loss: 0.4253 - val_dice_coef: 0.3236\n",
      "Epoch 3/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.3321 - dice_coef: 0.3845 - val_loss: 0.3457 - val_dice_coef: 0.3619\n",
      "Epoch 4/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.3043 - dice_coef: 0.3986 - val_loss: 0.3259 - val_dice_coef: 0.3982\n",
      "Epoch 5/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.2621 - dice_coef: 0.4615 - val_loss: 0.2987 - val_dice_coef: 0.4505\n",
      "Epoch 6/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.2370 - dice_coef: 0.4965 - val_loss: 0.2841 - val_dice_coef: 0.4529\n",
      "Epoch 7/250\n",
      "155/155 [==============================] - 6s 38ms/step - loss: 0.2279 - dice_coef: 0.5103 - val_loss: 0.2558 - val_dice_coef: 0.5313\n",
      "Epoch 8/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.2244 - dice_coef: 0.5069 - val_loss: 0.2576 - val_dice_coef: 0.5379\n",
      "Epoch 9/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.2011 - dice_coef: 0.5425 - val_loss: 0.2696 - val_dice_coef: 0.5509\n",
      "Epoch 10/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.2083 - dice_coef: 0.5837 - val_loss: 0.2381 - val_dice_coef: 0.5295\n",
      "Epoch 11/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.2005 - dice_coef: 0.5750 - val_loss: 0.2403 - val_dice_coef: 0.5796\n",
      "Epoch 12/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1756 - dice_coef: 0.6076 - val_loss: 0.2275 - val_dice_coef: 0.5541\n",
      "Epoch 13/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1703 - dice_coef: 0.6249 - val_loss: 0.2082 - val_dice_coef: 0.6241\n",
      "Epoch 14/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1624 - dice_coef: 0.6227 - val_loss: 0.2033 - val_dice_coef: 0.6440\n",
      "Epoch 15/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1615 - dice_coef: 0.6303 - val_loss: 0.2210 - val_dice_coef: 0.6250\n",
      "Epoch 16/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1515 - dice_coef: 0.6403 - val_loss: 0.1904 - val_dice_coef: 0.6189\n",
      "Epoch 17/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1635 - dice_coef: 0.6203 - val_loss: 0.2573 - val_dice_coef: 0.5423\n",
      "Epoch 18/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1531 - dice_coef: 0.6439 - val_loss: 0.1972 - val_dice_coef: 0.6538\n",
      "Epoch 19/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1479 - dice_coef: 0.6564 - val_loss: 0.1868 - val_dice_coef: 0.6354\n",
      "Epoch 20/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1642 - dice_coef: 0.6455 - val_loss: 0.1790 - val_dice_coef: 0.6508\n",
      "Epoch 21/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1412 - dice_coef: 0.6670 - val_loss: 0.1936 - val_dice_coef: 0.6272\n",
      "Epoch 22/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1372 - dice_coef: 0.6842 - val_loss: 0.1935 - val_dice_coef: 0.6708\n",
      "Epoch 23/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1431 - dice_coef: 0.6760 - val_loss: 0.1953 - val_dice_coef: 0.5956\n",
      "Epoch 24/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1419 - dice_coef: 0.6574 - val_loss: 0.2193 - val_dice_coef: 0.6241\n",
      "Epoch 25/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1370 - dice_coef: 0.6887 - val_loss: 0.1815 - val_dice_coef: 0.6750\n",
      "Epoch 26/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1277 - dice_coef: 0.7086 - val_loss: 0.1802 - val_dice_coef: 0.6737\n",
      "Epoch 27/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1231 - dice_coef: 0.7006 - val_loss: 0.1929 - val_dice_coef: 0.6161\n",
      "Epoch 28/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1429 - dice_coef: 0.6564 - val_loss: 0.1757 - val_dice_coef: 0.6799\n",
      "Epoch 29/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1270 - dice_coef: 0.7144 - val_loss: 0.1802 - val_dice_coef: 0.6600\n",
      "Epoch 30/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1242 - dice_coef: 0.7085 - val_loss: 0.1588 - val_dice_coef: 0.7052\n",
      "Epoch 31/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1151 - dice_coef: 0.7222 - val_loss: 0.1957 - val_dice_coef: 0.6755\n",
      "Epoch 32/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1101 - dice_coef: 0.7113 - val_loss: 0.1855 - val_dice_coef: 0.6490\n",
      "Epoch 33/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1200 - dice_coef: 0.6955 - val_loss: 0.1899 - val_dice_coef: 0.6702\n",
      "Epoch 34/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1240 - dice_coef: 0.6922 - val_loss: 0.1848 - val_dice_coef: 0.6766\n",
      "Epoch 35/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1084 - dice_coef: 0.7200 - val_loss: 0.1864 - val_dice_coef: 0.7040\n",
      "Epoch 36/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1041 - dice_coef: 0.7428 - val_loss: 0.2065 - val_dice_coef: 0.6898\n",
      "Epoch 37/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1066 - dice_coef: 0.7237 - val_loss: 0.1588 - val_dice_coef: 0.6919\n",
      "Epoch 38/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1041 - dice_coef: 0.7376 - val_loss: 0.1802 - val_dice_coef: 0.6939\n",
      "Epoch 39/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1315 - dice_coef: 0.6940 - val_loss: 0.1700 - val_dice_coef: 0.6934\n",
      "Epoch 40/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1074 - dice_coef: 0.7423 - val_loss: 0.1729 - val_dice_coef: 0.7028\n",
      "Epoch 41/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0985 - dice_coef: 0.7683 - val_loss: 0.1705 - val_dice_coef: 0.7100\n",
      "Epoch 42/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1083 - dice_coef: 0.7345 - val_loss: 0.2072 - val_dice_coef: 0.6938\n",
      "Epoch 43/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1082 - dice_coef: 0.7303 - val_loss: 0.2406 - val_dice_coef: 0.6119\n",
      "Epoch 44/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1115 - dice_coef: 0.7333 - val_loss: 0.1780 - val_dice_coef: 0.6918\n",
      "Epoch 45/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1008 - dice_coef: 0.7516 - val_loss: 0.1792 - val_dice_coef: 0.7154\n",
      "Epoch 46/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1059 - dice_coef: 0.7309 - val_loss: 0.1720 - val_dice_coef: 0.7075\n",
      "Epoch 47/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0988 - dice_coef: 0.7636 - val_loss: 0.1803 - val_dice_coef: 0.6795\n",
      "Epoch 48/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0988 - dice_coef: 0.7690 - val_loss: 0.1681 - val_dice_coef: 0.7313\n",
      "Epoch 49/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1074 - dice_coef: 0.7411 - val_loss: 0.1632 - val_dice_coef: 0.6901\n",
      "Epoch 50/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0905 - dice_coef: 0.7548 - val_loss: 0.1728 - val_dice_coef: 0.7276\n",
      "Epoch 51/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0878 - dice_coef: 0.7641 - val_loss: 0.1580 - val_dice_coef: 0.7311\n",
      "Epoch 52/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0895 - dice_coef: 0.7702 - val_loss: 0.1630 - val_dice_coef: 0.7196\n",
      "Epoch 53/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0929 - dice_coef: 0.7734 - val_loss: 0.1708 - val_dice_coef: 0.7185\n",
      "Epoch 54/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0893 - dice_coef: 0.7787 - val_loss: 0.1713 - val_dice_coef: 0.7360\n",
      "Epoch 55/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0920 - dice_coef: 0.7825 - val_loss: 0.1751 - val_dice_coef: 0.7231\n",
      "Epoch 56/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0898 - dice_coef: 0.7777 - val_loss: 0.1857 - val_dice_coef: 0.7111\n",
      "Epoch 57/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0936 - dice_coef: 0.7618 - val_loss: 0.1708 - val_dice_coef: 0.7019\n",
      "Epoch 58/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0895 - dice_coef: 0.7635 - val_loss: 0.2007 - val_dice_coef: 0.6891\n",
      "Epoch 59/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0822 - dice_coef: 0.8013 - val_loss: 0.1649 - val_dice_coef: 0.7401\n",
      "Epoch 60/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0887 - dice_coef: 0.7928 - val_loss: 0.1671 - val_dice_coef: 0.7254\n",
      "Epoch 61/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0871 - dice_coef: 0.7841 - val_loss: 0.1792 - val_dice_coef: 0.7138\n",
      "Epoch 62/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0933 - dice_coef: 0.7589 - val_loss: 0.1698 - val_dice_coef: 0.7278\n",
      "Epoch 63/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0968 - dice_coef: 0.7798 - val_loss: 0.1572 - val_dice_coef: 0.7293\n",
      "Epoch 64/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0909 - dice_coef: 0.7657 - val_loss: 0.1405 - val_dice_coef: 0.7354\n",
      "Epoch 65/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0865 - dice_coef: 0.7896 - val_loss: 0.1610 - val_dice_coef: 0.7357\n",
      "Epoch 66/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0948 - dice_coef: 0.7677 - val_loss: 0.1843 - val_dice_coef: 0.7255\n",
      "Epoch 67/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0804 - dice_coef: 0.7988 - val_loss: 0.1669 - val_dice_coef: 0.7346\n",
      "Epoch 68/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0854 - dice_coef: 0.7691 - val_loss: 0.1956 - val_dice_coef: 0.6825\n",
      "Epoch 69/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0876 - dice_coef: 0.7826 - val_loss: 0.1501 - val_dice_coef: 0.7475\n",
      "Epoch 70/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0857 - dice_coef: 0.7921 - val_loss: 0.1415 - val_dice_coef: 0.7385\n",
      "Epoch 71/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0787 - dice_coef: 0.7857 - val_loss: 0.1768 - val_dice_coef: 0.7308\n",
      "Epoch 72/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.1052 - dice_coef: 0.7590 - val_loss: 0.1766 - val_dice_coef: 0.7183\n",
      "Epoch 73/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0831 - dice_coef: 0.8012 - val_loss: 0.1474 - val_dice_coef: 0.7355\n",
      "Epoch 74/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0784 - dice_coef: 0.7984 - val_loss: 0.1566 - val_dice_coef: 0.7421\n",
      "Epoch 75/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0799 - dice_coef: 0.8047 - val_loss: 0.2660 - val_dice_coef: 0.6964\n",
      "Epoch 76/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0828 - dice_coef: 0.7772 - val_loss: 0.1764 - val_dice_coef: 0.7454\n",
      "Epoch 77/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0758 - dice_coef: 0.8031 - val_loss: 0.1588 - val_dice_coef: 0.7493\n",
      "Epoch 78/250\n",
      "155/155 [==============================] - 6s 36ms/step - loss: 0.0802 - dice_coef: 0.8167 - val_loss: 0.1665 - val_dice_coef: 0.7475\n",
      "Epoch 79/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0810 - dice_coef: 0.8026 - val_loss: 0.1619 - val_dice_coef: 0.7473\n",
      "Epoch 80/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0900 - dice_coef: 0.7927 - val_loss: 0.2280 - val_dice_coef: 0.7283\n",
      "Epoch 81/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0782 - dice_coef: 0.8195 - val_loss: 0.1513 - val_dice_coef: 0.7547\n",
      "Epoch 82/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0751 - dice_coef: 0.8234 - val_loss: 0.1649 - val_dice_coef: 0.7547\n",
      "Epoch 83/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0762 - dice_coef: 0.8052 - val_loss: 0.1478 - val_dice_coef: 0.7496\n",
      "Epoch 84/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0752 - dice_coef: 0.8085 - val_loss: 0.1515 - val_dice_coef: 0.7484\n",
      "Epoch 85/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0778 - dice_coef: 0.8112 - val_loss: 0.1454 - val_dice_coef: 0.7535\n",
      "Epoch 86/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0725 - dice_coef: 0.8177 - val_loss: 0.1373 - val_dice_coef: 0.7513\n",
      "Epoch 87/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0786 - dice_coef: 0.8150 - val_loss: 0.1469 - val_dice_coef: 0.7625\n",
      "Epoch 88/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0756 - dice_coef: 0.8255 - val_loss: 0.1476 - val_dice_coef: 0.7561\n",
      "Epoch 89/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0643 - dice_coef: 0.8354 - val_loss: 0.1558 - val_dice_coef: 0.7629\n",
      "Epoch 90/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0716 - dice_coef: 0.8034 - val_loss: 0.1454 - val_dice_coef: 0.7685\n",
      "Epoch 91/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0819 - dice_coef: 0.8054 - val_loss: 0.1423 - val_dice_coef: 0.7501\n",
      "Epoch 92/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0791 - dice_coef: 0.8011 - val_loss: 0.1520 - val_dice_coef: 0.7236\n",
      "Epoch 93/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0721 - dice_coef: 0.8205 - val_loss: 0.1580 - val_dice_coef: 0.7591\n",
      "Epoch 94/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0735 - dice_coef: 0.8163 - val_loss: 0.1709 - val_dice_coef: 0.7691\n",
      "Epoch 95/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0719 - dice_coef: 0.8158 - val_loss: 0.1406 - val_dice_coef: 0.7620\n",
      "Epoch 96/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0744 - dice_coef: 0.8290 - val_loss: 0.1567 - val_dice_coef: 0.7685\n",
      "Epoch 97/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0664 - dice_coef: 0.8335 - val_loss: 0.1480 - val_dice_coef: 0.7641\n",
      "Epoch 98/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0794 - dice_coef: 0.8103 - val_loss: 0.1515 - val_dice_coef: 0.7375\n",
      "Epoch 99/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0701 - dice_coef: 0.8373 - val_loss: 0.1535 - val_dice_coef: 0.7427\n",
      "Epoch 100/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0732 - dice_coef: 0.8303 - val_loss: 0.1367 - val_dice_coef: 0.7746\n",
      "Epoch 101/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0735 - dice_coef: 0.8161 - val_loss: 0.1354 - val_dice_coef: 0.7657\n",
      "Epoch 102/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0693 - dice_coef: 0.8239 - val_loss: 0.1571 - val_dice_coef: 0.7758\n",
      "Epoch 103/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0717 - dice_coef: 0.8349 - val_loss: 0.1410 - val_dice_coef: 0.7577\n",
      "Epoch 104/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0772 - dice_coef: 0.8143 - val_loss: 0.1360 - val_dice_coef: 0.7579\n",
      "Epoch 105/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0685 - dice_coef: 0.8253 - val_loss: 0.1399 - val_dice_coef: 0.7746\n",
      "Epoch 106/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0685 - dice_coef: 0.8417 - val_loss: 0.1461 - val_dice_coef: 0.7673\n",
      "Epoch 107/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0674 - dice_coef: 0.8355 - val_loss: 0.1625 - val_dice_coef: 0.7491\n",
      "Epoch 108/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0789 - dice_coef: 0.8048 - val_loss: 0.1979 - val_dice_coef: 0.6992\n",
      "Epoch 109/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0762 - dice_coef: 0.7975 - val_loss: 0.1566 - val_dice_coef: 0.7524\n",
      "Epoch 110/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0719 - dice_coef: 0.8310 - val_loss: 0.1518 - val_dice_coef: 0.7627\n",
      "Epoch 111/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0763 - dice_coef: 0.8165 - val_loss: 0.1787 - val_dice_coef: 0.7613\n",
      "Epoch 112/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0726 - dice_coef: 0.8312 - val_loss: 0.1558 - val_dice_coef: 0.7579\n",
      "Epoch 113/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0817 - dice_coef: 0.8042 - val_loss: 0.1622 - val_dice_coef: 0.7443\n",
      "Epoch 114/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0677 - dice_coef: 0.8313 - val_loss: 0.1675 - val_dice_coef: 0.7590\n",
      "Epoch 115/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0684 - dice_coef: 0.8424 - val_loss: 0.1874 - val_dice_coef: 0.7562\n",
      "Epoch 116/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0649 - dice_coef: 0.8532 - val_loss: 0.1549 - val_dice_coef: 0.7605\n",
      "Epoch 117/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0645 - dice_coef: 0.8503 - val_loss: 0.1522 - val_dice_coef: 0.7540\n",
      "Epoch 118/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0726 - dice_coef: 0.8286 - val_loss: 0.1770 - val_dice_coef: 0.7642\n",
      "Epoch 119/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0644 - dice_coef: 0.8400 - val_loss: 0.1525 - val_dice_coef: 0.7781\n",
      "Epoch 120/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0609 - dice_coef: 0.8524 - val_loss: 0.1492 - val_dice_coef: 0.7777\n",
      "Epoch 121/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0685 - dice_coef: 0.8278 - val_loss: 0.1523 - val_dice_coef: 0.7564\n",
      "Epoch 122/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0641 - dice_coef: 0.8388 - val_loss: 0.1462 - val_dice_coef: 0.7622\n",
      "Epoch 123/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0675 - dice_coef: 0.8355 - val_loss: 0.1515 - val_dice_coef: 0.7698\n",
      "Epoch 124/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0628 - dice_coef: 0.8633 - val_loss: 0.1545 - val_dice_coef: 0.7724\n",
      "Epoch 125/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0631 - dice_coef: 0.8525 - val_loss: 0.1493 - val_dice_coef: 0.7531\n",
      "Epoch 126/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0649 - dice_coef: 0.8458 - val_loss: 0.1477 - val_dice_coef: 0.7690\n",
      "Epoch 127/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0664 - dice_coef: 0.8525 - val_loss: 0.1637 - val_dice_coef: 0.7639\n",
      "Epoch 128/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0737 - dice_coef: 0.8177 - val_loss: 0.1502 - val_dice_coef: 0.7350\n",
      "Epoch 129/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0643 - dice_coef: 0.8399 - val_loss: 0.1573 - val_dice_coef: 0.7663\n",
      "Epoch 130/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0583 - dice_coef: 0.8533 - val_loss: 0.1619 - val_dice_coef: 0.7714\n",
      "Epoch 131/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0623 - dice_coef: 0.8533 - val_loss: 0.1749 - val_dice_coef: 0.7658\n",
      "Epoch 132/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0632 - dice_coef: 0.8576 - val_loss: 0.1459 - val_dice_coef: 0.7819\n",
      "Epoch 133/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0611 - dice_coef: 0.8571 - val_loss: 0.1421 - val_dice_coef: 0.7736\n",
      "Epoch 134/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0619 - dice_coef: 0.8581 - val_loss: 0.1488 - val_dice_coef: 0.7741\n",
      "Epoch 135/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0620 - dice_coef: 0.8567 - val_loss: 0.1528 - val_dice_coef: 0.7674\n",
      "Epoch 136/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0611 - dice_coef: 0.8514 - val_loss: 0.1492 - val_dice_coef: 0.7815\n",
      "Epoch 137/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0585 - dice_coef: 0.8607 - val_loss: 0.1683 - val_dice_coef: 0.7814\n",
      "Epoch 138/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0617 - dice_coef: 0.8701 - val_loss: 0.1746 - val_dice_coef: 0.7734\n",
      "Epoch 139/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0600 - dice_coef: 0.8646 - val_loss: 0.1575 - val_dice_coef: 0.7851\n",
      "Epoch 140/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0571 - dice_coef: 0.8668 - val_loss: 0.1615 - val_dice_coef: 0.7723\n",
      "Epoch 141/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0597 - dice_coef: 0.8566 - val_loss: 0.1516 - val_dice_coef: 0.7831\n",
      "Epoch 142/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0608 - dice_coef: 0.8582 - val_loss: 0.1435 - val_dice_coef: 0.7840\n",
      "Epoch 143/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0614 - dice_coef: 0.8650 - val_loss: 0.1471 - val_dice_coef: 0.7809\n",
      "Epoch 144/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0601 - dice_coef: 0.8551 - val_loss: 0.1412 - val_dice_coef: 0.7814\n",
      "Epoch 145/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0608 - dice_coef: 0.8540 - val_loss: 0.1562 - val_dice_coef: 0.7889\n",
      "Epoch 146/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0610 - dice_coef: 0.8713 - val_loss: 0.1453 - val_dice_coef: 0.7988\n",
      "Epoch 147/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0757 - dice_coef: 0.8290 - val_loss: 0.1741 - val_dice_coef: 0.7579\n",
      "Epoch 148/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0670 - dice_coef: 0.8372 - val_loss: 0.1805 - val_dice_coef: 0.7324\n",
      "Epoch 149/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0854 - dice_coef: 0.7935 - val_loss: 0.1574 - val_dice_coef: 0.7456\n",
      "Epoch 150/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0588 - dice_coef: 0.8539 - val_loss: 0.1477 - val_dice_coef: 0.7660\n",
      "Epoch 151/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0610 - dice_coef: 0.8526 - val_loss: 0.1754 - val_dice_coef: 0.7608\n",
      "Epoch 152/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0638 - dice_coef: 0.8498 - val_loss: 0.1469 - val_dice_coef: 0.7903\n",
      "Epoch 153/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0617 - dice_coef: 0.8568 - val_loss: 0.1686 - val_dice_coef: 0.7582\n",
      "Epoch 154/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0599 - dice_coef: 0.8526 - val_loss: 0.1568 - val_dice_coef: 0.7855\n",
      "Epoch 155/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0607 - dice_coef: 0.8608 - val_loss: 0.1539 - val_dice_coef: 0.7825\n",
      "Epoch 156/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0576 - dice_coef: 0.8675 - val_loss: 0.1493 - val_dice_coef: 0.7736\n",
      "Epoch 157/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0565 - dice_coef: 0.8651 - val_loss: 0.1542 - val_dice_coef: 0.7798\n",
      "Epoch 158/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0560 - dice_coef: 0.8681 - val_loss: 0.1532 - val_dice_coef: 0.7881\n",
      "Epoch 159/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0535 - dice_coef: 0.8741 - val_loss: 0.1629 - val_dice_coef: 0.7824\n",
      "Epoch 160/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0540 - dice_coef: 0.8749 - val_loss: 0.1551 - val_dice_coef: 0.7894\n",
      "Epoch 161/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0577 - dice_coef: 0.8606 - val_loss: 0.1426 - val_dice_coef: 0.7802\n",
      "Epoch 162/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0534 - dice_coef: 0.8700 - val_loss: 0.1485 - val_dice_coef: 0.7866\n",
      "Epoch 163/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0560 - dice_coef: 0.8694 - val_loss: 0.1457 - val_dice_coef: 0.7856\n",
      "Epoch 164/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0550 - dice_coef: 0.8803 - val_loss: 0.1463 - val_dice_coef: 0.7836\n",
      "Epoch 165/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0574 - dice_coef: 0.8727 - val_loss: 0.1609 - val_dice_coef: 0.7632\n",
      "Epoch 166/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0646 - dice_coef: 0.8532 - val_loss: 0.1421 - val_dice_coef: 0.7888\n",
      "Epoch 167/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0575 - dice_coef: 0.8689 - val_loss: 0.1426 - val_dice_coef: 0.7861\n",
      "Epoch 168/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0576 - dice_coef: 0.8785 - val_loss: 0.1419 - val_dice_coef: 0.7819\n",
      "Epoch 169/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0514 - dice_coef: 0.8746 - val_loss: 0.1458 - val_dice_coef: 0.7938\n",
      "Epoch 170/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0537 - dice_coef: 0.8733 - val_loss: 0.1613 - val_dice_coef: 0.7777\n",
      "Epoch 171/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0532 - dice_coef: 0.8734 - val_loss: 0.1503 - val_dice_coef: 0.7897\n",
      "Epoch 172/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0638 - dice_coef: 0.8604 - val_loss: 0.1816 - val_dice_coef: 0.7501\n",
      "Epoch 173/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0606 - dice_coef: 0.8646 - val_loss: 0.1423 - val_dice_coef: 0.7855\n",
      "Epoch 174/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0630 - dice_coef: 0.8702 - val_loss: 0.1401 - val_dice_coef: 0.7896\n",
      "Epoch 175/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0541 - dice_coef: 0.8723 - val_loss: 0.1553 - val_dice_coef: 0.7883\n",
      "Epoch 176/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0565 - dice_coef: 0.8727 - val_loss: 0.1519 - val_dice_coef: 0.7898\n",
      "Epoch 177/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0542 - dice_coef: 0.8739 - val_loss: 0.1503 - val_dice_coef: 0.7878\n",
      "Epoch 178/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0515 - dice_coef: 0.8720 - val_loss: 0.1545 - val_dice_coef: 0.7843\n",
      "Epoch 179/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0544 - dice_coef: 0.8759 - val_loss: 0.1635 - val_dice_coef: 0.7838\n",
      "Epoch 180/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0571 - dice_coef: 0.8726 - val_loss: 0.1612 - val_dice_coef: 0.7687\n",
      "Epoch 181/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0533 - dice_coef: 0.8756 - val_loss: 0.1445 - val_dice_coef: 0.7881\n",
      "Epoch 182/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0567 - dice_coef: 0.8750 - val_loss: 0.1539 - val_dice_coef: 0.7845\n",
      "Epoch 183/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0533 - dice_coef: 0.8785 - val_loss: 0.1500 - val_dice_coef: 0.7934\n",
      "Epoch 184/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0533 - dice_coef: 0.8801 - val_loss: 0.1597 - val_dice_coef: 0.7898\n",
      "Epoch 185/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0522 - dice_coef: 0.8788 - val_loss: 0.1656 - val_dice_coef: 0.7903\n",
      "Epoch 186/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0705 - dice_coef: 0.8476 - val_loss: 0.1580 - val_dice_coef: 0.7455\n",
      "Epoch 187/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0583 - dice_coef: 0.8647 - val_loss: 0.1397 - val_dice_coef: 0.7871\n",
      "Epoch 188/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0549 - dice_coef: 0.8779 - val_loss: 0.1485 - val_dice_coef: 0.7910\n",
      "Epoch 189/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0554 - dice_coef: 0.8793 - val_loss: 0.1421 - val_dice_coef: 0.7953\n",
      "Epoch 190/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0531 - dice_coef: 0.8742 - val_loss: 0.1420 - val_dice_coef: 0.7923\n",
      "Epoch 191/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0533 - dice_coef: 0.8876 - val_loss: 0.1498 - val_dice_coef: 0.7950\n",
      "Epoch 192/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0513 - dice_coef: 0.8790 - val_loss: 0.1504 - val_dice_coef: 0.7991\n",
      "Epoch 193/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0528 - dice_coef: 0.8856 - val_loss: 0.1522 - val_dice_coef: 0.7946\n",
      "Epoch 194/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0529 - dice_coef: 0.8811 - val_loss: 0.1615 - val_dice_coef: 0.7939\n",
      "Epoch 195/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0527 - dice_coef: 0.8842 - val_loss: 0.1403 - val_dice_coef: 0.8013\n",
      "Epoch 196/250\n",
      "155/155 [==============================] - 6s 36ms/step - loss: 0.0514 - dice_coef: 0.8843 - val_loss: 0.1333 - val_dice_coef: 0.8012\n",
      "Epoch 197/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0665 - dice_coef: 0.8395 - val_loss: 0.1435 - val_dice_coef: 0.7846\n",
      "Epoch 198/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0589 - dice_coef: 0.8647 - val_loss: 0.1729 - val_dice_coef: 0.7798\n",
      "Epoch 199/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0533 - dice_coef: 0.8767 - val_loss: 0.1475 - val_dice_coef: 0.7885\n",
      "Epoch 200/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0523 - dice_coef: 0.8830 - val_loss: 0.1555 - val_dice_coef: 0.7931\n",
      "Epoch 201/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0515 - dice_coef: 0.8849 - val_loss: 0.1488 - val_dice_coef: 0.7929\n",
      "Epoch 202/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0506 - dice_coef: 0.8896 - val_loss: 0.2118 - val_dice_coef: 0.7707\n",
      "Epoch 203/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0506 - dice_coef: 0.8808 - val_loss: 0.1596 - val_dice_coef: 0.7977\n",
      "Epoch 204/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0514 - dice_coef: 0.8845 - val_loss: 0.1429 - val_dice_coef: 0.7986\n",
      "Epoch 205/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0507 - dice_coef: 0.8837 - val_loss: 0.1487 - val_dice_coef: 0.7970\n",
      "Epoch 206/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0493 - dice_coef: 0.8918 - val_loss: 0.1656 - val_dice_coef: 0.7944\n",
      "Epoch 207/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0550 - dice_coef: 0.8787 - val_loss: 0.1458 - val_dice_coef: 0.8021\n",
      "Epoch 208/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0539 - dice_coef: 0.8848 - val_loss: 0.1559 - val_dice_coef: 0.7925\n",
      "Epoch 209/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0563 - dice_coef: 0.8789 - val_loss: 0.1498 - val_dice_coef: 0.7887\n",
      "Epoch 210/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0518 - dice_coef: 0.8849 - val_loss: 0.1845 - val_dice_coef: 0.7751\n",
      "Epoch 211/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0699 - dice_coef: 0.8493 - val_loss: 0.1653 - val_dice_coef: 0.7764\n",
      "Epoch 212/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0563 - dice_coef: 0.8646 - val_loss: 0.1610 - val_dice_coef: 0.7825\n",
      "Epoch 213/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0526 - dice_coef: 0.8831 - val_loss: 0.1539 - val_dice_coef: 0.7907\n",
      "Epoch 214/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0494 - dice_coef: 0.8814 - val_loss: 0.1558 - val_dice_coef: 0.7944\n",
      "Epoch 215/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0500 - dice_coef: 0.8921 - val_loss: 0.1423 - val_dice_coef: 0.7946\n",
      "Epoch 216/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0507 - dice_coef: 0.8862 - val_loss: 0.1501 - val_dice_coef: 0.7960\n",
      "Epoch 217/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0552 - dice_coef: 0.8712 - val_loss: 0.1426 - val_dice_coef: 0.7988\n",
      "Epoch 218/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0517 - dice_coef: 0.8833 - val_loss: 0.1464 - val_dice_coef: 0.7987\n",
      "Epoch 219/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0496 - dice_coef: 0.8865 - val_loss: 0.1440 - val_dice_coef: 0.8012\n",
      "Epoch 220/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0513 - dice_coef: 0.8883 - val_loss: 0.1488 - val_dice_coef: 0.8006\n",
      "Epoch 221/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0510 - dice_coef: 0.8870 - val_loss: 0.1422 - val_dice_coef: 0.7989\n",
      "Epoch 222/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0634 - dice_coef: 0.8653 - val_loss: 0.1544 - val_dice_coef: 0.7782\n",
      "Epoch 223/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0513 - dice_coef: 0.8821 - val_loss: 0.1520 - val_dice_coef: 0.7883\n",
      "Epoch 224/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0504 - dice_coef: 0.8891 - val_loss: 0.1542 - val_dice_coef: 0.7955\n",
      "Epoch 225/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0503 - dice_coef: 0.8905 - val_loss: 0.1541 - val_dice_coef: 0.8007\n",
      "Epoch 226/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0515 - dice_coef: 0.8890 - val_loss: 0.1575 - val_dice_coef: 0.7955\n",
      "Epoch 227/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0481 - dice_coef: 0.8948 - val_loss: 0.1634 - val_dice_coef: 0.7894\n",
      "Epoch 228/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0500 - dice_coef: 0.8904 - val_loss: 0.1583 - val_dice_coef: 0.7968\n",
      "Epoch 229/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0510 - dice_coef: 0.8926 - val_loss: 0.1470 - val_dice_coef: 0.7956\n",
      "Epoch 230/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0503 - dice_coef: 0.8936 - val_loss: 0.1652 - val_dice_coef: 0.7931\n",
      "Epoch 231/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0488 - dice_coef: 0.8951 - val_loss: 0.1546 - val_dice_coef: 0.7963\n",
      "Epoch 232/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0490 - dice_coef: 0.8936 - val_loss: 0.1682 - val_dice_coef: 0.7971\n",
      "Epoch 233/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0487 - dice_coef: 0.8914 - val_loss: 0.1679 - val_dice_coef: 0.7901\n",
      "Epoch 234/250\n",
      "155/155 [==============================] - 6s 36ms/step - loss: 0.0487 - dice_coef: 0.8952 - val_loss: 0.1507 - val_dice_coef: 0.7918\n",
      "Epoch 235/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0476 - dice_coef: 0.8943 - val_loss: 0.1593 - val_dice_coef: 0.7927\n",
      "Epoch 236/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0459 - dice_coef: 0.8970 - val_loss: 0.1614 - val_dice_coef: 0.7976\n",
      "Epoch 237/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0517 - dice_coef: 0.8911 - val_loss: 0.1395 - val_dice_coef: 0.7751\n",
      "Epoch 238/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0518 - dice_coef: 0.8871 - val_loss: 0.1473 - val_dice_coef: 0.7927\n",
      "Epoch 239/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0479 - dice_coef: 0.8928 - val_loss: 0.1473 - val_dice_coef: 0.7959\n",
      "Epoch 240/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0477 - dice_coef: 0.8939 - val_loss: 0.1544 - val_dice_coef: 0.7935\n",
      "Epoch 241/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0482 - dice_coef: 0.8958 - val_loss: 0.1514 - val_dice_coef: 0.8038\n",
      "Epoch 242/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0482 - dice_coef: 0.8992 - val_loss: 0.1483 - val_dice_coef: 0.8036\n",
      "Epoch 243/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0651 - dice_coef: 0.8624 - val_loss: 0.2469 - val_dice_coef: 0.7306\n",
      "Epoch 244/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0701 - dice_coef: 0.8370 - val_loss: 0.1343 - val_dice_coef: 0.7916\n",
      "Epoch 245/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0507 - dice_coef: 0.8772 - val_loss: 0.1374 - val_dice_coef: 0.8023\n",
      "Epoch 246/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0532 - dice_coef: 0.8865 - val_loss: 0.1718 - val_dice_coef: 0.7827\n",
      "Epoch 247/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0521 - dice_coef: 0.8881 - val_loss: 0.1452 - val_dice_coef: 0.8018\n",
      "Epoch 248/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0468 - dice_coef: 0.8944 - val_loss: 0.1433 - val_dice_coef: 0.8093\n",
      "Epoch 249/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0485 - dice_coef: 0.8938 - val_loss: 0.1431 - val_dice_coef: 0.8088\n",
      "Epoch 250/250\n",
      "155/155 [==============================] - 6s 37ms/step - loss: 0.0503 - dice_coef: 0.8971 - val_loss: 0.1460 - val_dice_coef: 0.8090\n"
     ]
    }
   ],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "history = model.fit(train_gen, \n",
    "          validation_data = valid_gen, \n",
    "          steps_per_epoch = train_steps, \n",
    "          validation_steps = valid_steps, \n",
    "          epochs = 250, callbacks=[WandbMetricsLogger()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee75ce95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 314ms/step\n",
      "[  0. 255.]\n"
     ]
    }
   ],
   "source": [
    "# get the test set images\n",
    "test_images, test_masks = train_gen.__getitem__(100)\n",
    "predicted_masks = model.predict(test_images)\n",
    "# print(predicted_masks[0])\n",
    "op = np.zeros((64, 64))\n",
    "for i in range(0, len(predicted_masks[0])):\n",
    "    for j in range(0, len(predicted_masks[0])):\n",
    "#         print(predicted_masks[0][i][j][0])\n",
    "        if predicted_masks[0][i][j][0] > 0.15:\n",
    "            op[i][j] = 255\n",
    "        else:\n",
    "            op[i][j] = 0\n",
    "print(np.unique(op))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f09aba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48a10212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAACcCAYAAABBRnGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABFv0lEQVR4nO29eZxlZ1nv+31rz2PN1TV09Zzupju5MUGCU4KAIAqOB1EJKErkAh49V+Gco4JMiooi6BFlPIxxALyRAwhKgEtkahI6how9pKu7qmsedu153vXeP9Z63rx7pzrdVelOdSfv9/OpT1Xtvaa9197PetYz/B6ltcbhcDgcTzxdW30ADofD8VTFGWCHw+HYIpwBdjgcji3CGWCHw+HYIpwBdjgcji3CGWCHw+HYIpwBvkJRSr1FKbW81cdxMVFKhZRSf6aUmlFKFZRS31FKvegC192llNL+zw+v8/wf+s+ducjHLPs973Eqpf5GKfWRDWz7X5VSf/j4jtBxOeMMsONy4n8C/w34E+DFwFeB79/gNorAL6/z+C/6z20JSqlx4BbgHRtY7c+A31VK9VySg3JsOc4AOy4nfgb4R63132qt/11r/fta67dscBufA16slArIA0qpa4CnAZ+/eIe6YV4N3K21PnahK2itvw6sAC+/ZEfl2FKcAX6SoJT6Uf9W+LlKqf+jlCoppU4qpZ6vlAoopf5CKbXs397/bse6P6iU+qxSatZf7x6l1M3n2Me9SqmqUuoupdQN/jbf0rHczyilvusvN6+U+nOlVOgCXkYL2Pe43gj4P0AKeLb12C8B3wBmOo4zoZR6j1LquFKqrJQ6rZT6W6VUumO5VyqlHlBKVfzXe4dS6vC5DsB/nwpKqT+xHv4V4J87ljuslPo3pVTGf98fUkr9Zsfm/l9/XceTEGeAn3y8H8/Y/Bwwifelfw+eUXqp//9fKqV+wFpnJ/BNvFvkn8L70n9EKWVu5ZVSY8AXgEW88MD7gb8HYvbOlVIvAW4D7gR+Gngr8CrgTy/g2P8BuFEp9ZoNveJ2Snierh2G+CXgH9dZNg4EgDcAPwH8IfAc4NOygFLqJuB9wK3+Mr8OfAvoXm/nSqkfx3uf/kJr/Qf+YweA7f56Np/Fu+i8DO+9+hu882TzLeDpSqnex3jNjisVrbX7uQJ/gLcAy9b/Pwpo4M3WY4f8x75qPdYFzAPvOMd2FRDEM7D2en8BLAMx67GX+Nt/i7XuJPCRjm3+OlAB+h/j9YTwDPrDQBN40Qbfj13+sbwI7+KTAcLADUADGADeCZx5jG0EgR/2t7PDf+z1wNEL3O9PA1Xg9R3LvNRfJmE9NuA/ds0Fvq7nbfVnzv1c/B/nAT/5+Ir198P+76/KA1rrNWACGJPHlFK9Sqn/pZSaxDNWDTyvdb+1rWcAt2utK9Zjn+3Y935gB/AppVRQfvz9R4GrH+O4/xi41l/mQ8AnbS/dDwG88zHWt/kCnmf743je71e01utWjCilXq6U+k+lVBHvdX/Dei0A9wDXKaXerZS6SSkVPsc+/wue5/w6rXXncQ4DVa11yXosA5wF3qeU+kWl1NA5tivHPXyO5x1XMM4AP/nIyh9a63rnYz51PIMofBSvSuAvgOfjGdsPdywzDCzZG9FaV2mvLBjwf3+BRwx5AzjtPz6+3gH78eH/CrzH3+ZrgS8Cn1dKHVBKJfFiw7evt34nWusa8Bk8z/MlwD+dY78/B3wc+DbwC8AP4HnP4L92rfWXgV8DbgK+Biwrpf5OKZXo2NxP4xnVf1lnV1Gg1nGMa3jv9Tzeez2vlPq6Uuq6jnVlvSiOJx3BrT4Ax9ailIoCLwT+q9b6fdbjnRfneWBwnXWT1kMZ//ergP9cZ3en13kMPMMdBwrgGSc/CfhF4N/xYsqnuEAD7PNPeLHgBusbRfCM7ne01q+VB5RSz+pcSGv9MeBjSqlB4OeBdwN54PesxX4L+F3gdqXUTVrrFeu5DJBWSnX5hle2ewz4L/4F6Ea8ErV/VUptt5brsbbheJLhPGBHBO923XhoSqkUnkdncxfwPKWUnXTrXOY4XqXBLq31d9f5WWF9FvHKrV4iD/he7M/iGeXfAX7fNl4XwO14ycQ/11rnzrFMjA7PFHhU9Yd1TEta6/cDX8eLr9vk8UIeGvj3jkqK43jx8Z3n2G5Da/1V4F3ACI8YXfBiwAAnznVcjisX5wE/xdFa55RSdwFvUkrlgTU8zy4H2Ebkr4DfBD6nlHo3Xkji94Cyv454rq8DPuEboC/ihTv24BnTF2uty+scQ0sp9UbgvUqp2/BCIi3gucBVeN73Hyilbl9v/XO8riaWQT8HtwN/q5R6A/Ad4Cf9fRqUUm8F+vDDD8B1wLNo935lnytKqefhGejPK6Ve4B/vnXiJxafj3wUopf4vvKTgJ/Fi8r14jSjf01rb3u73452LBy7kdTuuLJwH7AAvVnoaLx7613ie48ftBbTWM3ihiiG8kMBv4VU3BPC8P1nuk3gNFd+Hl5S6DS+mezeeMV4XP/zxErxyrU/hlaQdBJ6HF389CPyT3WBxEXg/8Jd43Xe34XmoL+1Y5i48b/d9eOGQ1+BVoPz1OV7HHJ4R3wXcppQK+8m3f8crYxPmgQW8ErgvAn8HPMSj7ypeAPzLBr1/xxWC0tqNJHJsDqXUj+B5e8/RWv9/W308lzN+wu9DwKgfXrmQdbrxjPSPaa2/cb7lHVcezgA7Lhil1DvwkmvzwAG8xoUV4DrnoT02SikFfA/4X1rrD13gOr8HvEBr/aOX8tgcW4eLATs2QgSvVG0bXnLsS8DvOuN7frTWWin1KrwL14WSA377Eh2S4zLAecAOh8OxRbgknMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFvGEGWCl1PuUUn/4RO3vUqGUKiql9mz1cTyVUEr9gVLqQiUcL3jZC9iWVkrtuxjbclw8lFIfVUr9sf/3jUqp40/Qfi/65+GiGGCl1BmlVF0pNdDx+D3+Qe/SWr9aa/1HF2N/W4nWOqm1ntjq47iSUUq9Qil1n1KqrJSaV0q9VynVc67ltdZ/orW+5UK2vZFlHZcW3y5UfKdlQSn1EX/C9UVDa/11rfV5JT79z9xlJ2p/MT3g08Avyz9KqWvwhh5uGuXhwiRPIvyZce8A/jvQjTcKfifeNOHwOss7zeorm5/SWieB64FnAG+0n3yqn9+Ladw+AfyK9f+vYs0Vs28b/P9/xveQ80qpU0qpF/iPf00p9Xal1DfxBj7uUUr9kFLqLqVUzv/9Q9Z2XqGUmlBKFZRSp/1x5vLcbyilHvKfe1Apdb3/+NP8/WSVUg8opX664zjfp5S63V/vDqXUTut5cxuilIoppf5SKTXpH9s3OqYGOyz8QZ1vBX5La/1v/jTgM3iz4HYCL1NKvUUp9c9KqVv9IaGv8B+71drOr/jv+YpS6g99T+vH/OfMskqpXf75+lWl1JRSall5AzhlOzcopb7tfw7mlFLvWe8i4Hj8+DMFvwhc7Z+T31RKnQROAiilXuTbg6xS6lvKG1qK/9x1Sqm7/e/jJ4Go9dyPKqWmrf/HlVK3KaWW/M/He5RST8Ob6feDvjee9ZeNKKXe6X82Fvzvfcza1n/3PxezSqlfv1RvzOP+Ac4AP4Y3fvtpeIMaz+J9qTTegMKPAn/sL38Dntr/8/AuAmPAQf+5rwFTwGG8iR3bgFXg5f7/v+z/3w8k8AZCHvDXHQEO+3//At6I9GfgjQTf5x9PCHgY+AMgDDwHb7qDbOOj/v834U2A+GvgG9Zr1cA+/++/9Y93zH/NPwRELsZ7+mT8wRsw2QSC6zz3MeAf8QZeNvCmKHfh3UW9BbjVX+4QUAR+xD9/7/SX/zH/eXvZXf75+qC/nWvxxtA/zX/+6XgeeNBf9iHg/1nvXLufTZ3vM9Z5Gceb7PxH/vt6O9606Ried7wIPNP/Hv2qv27EP8eTwO/4390X++dbbMmPAtP+3wG8sU/v9m1DFPgR/7lX2N9j/7G/Aj7rH0cK+Bzwp9ZndQG42t/WP1yKz8PFvr0XL/h5wDE8A7gerwQ+rLW+XWu9prWe0Vofs57/qNb6Ae2NFn8+cFJr/QmtdVNr/Y/+tn/KX3YN76oa01rPaa1lfPctwJ9rre/SHg9rrSfxvnBJ4M+01nWt9VeBz2OFT4B/1Vr/h/aGJ74B78o5br8APzTy68B/84+/pbX+lr7AgYtPUQaAZf+8djLnPw/wba31Z/zPRqVjuRcDn9Naf0NrXQfehPfFeCzeqrWuaK2/h/cFvRZAa31Ua33E/1ydwZuS/KzNvTTHOfiM73F+A7gD+BP/8T/VWmf88/sbwPu11t/xv0cfw7tQ/oD/EwL+Snt3TP+MN6l6PW4ARoH/rrUuaa2r+hzDTJVSyt/v7/jHUfCP7Zf8RV4CfERrfb/2plq/5fG8CefiYsdfPgH8B7CbjrHmHYwDX3iM589af4/iXQFtJoExrXVJKfWLwOuB/+2HLV7nG/Nx4NQ62x4Fzur2OWaTeF7so/avtS4qpTKynrXMAN4Vdr19ONZnGRhQSgXXMcIj/vPQ/j530nYetNZlpdTKefY7b/1dxrsAo5TaD7wL+H4gjvd9OHq+F+HYED+rtf6y/YBn+9rO8U7gV5VSv2U9FsY71xqY0b5b6tNpD4RxYPIcF/hOBvHO+VH/eMC7Uw74f4/S/lk41z4fFxfVA/Y9zNPATwK3PcaiZ4G9j7Up6+9ZvBNkswPfu9Za/7vW+nl4X+BjeLebj7WPWWBctSf3zPZ8jLervKxtn7+ezTJQPc/rcLTzbTzP5uftB5VSCeAngK/4Dz2WRzsHbLfWjeGFozbDe/E+M1dprdN4YSn12Ks4LhL2OT4LvF1r3WP9xP273TlgTFlWEu/7uh5ngR1q/cRe52dqGajghSxln93aSxji79e+6z3XPh8Xl6LC4JXAc3y3/Vz8b+DXlFLPVUp1KaXGlFIHz7HsF4D9SqmXKqWCvsd7CPi8UmqbUuqn/S9wDS822PLX+xDweqXU05XHPj+Z9h2gBPwPpVRIKfWjeOGMf7L2+ZNKqR/xEzJ/BHxHa93mlfke9IeBdymlRpVSAaXUDyqlIhf6Rj3V0Frn8JJwf6OUeoH//u8CPg1M491BnY9/Bn5KeYnZsL+9zRrNFF4Ooeh//l6zye04Hh8fBF6tlHqm/11NKKVeqJRK4V20m8Bv+9//n8cLNazHnXiG88/8bUSVUj/sP7cAbJckq//9/SDwbqXUEIBvh37cX/5TeAngQ0qpOPDmS/C6L74B1lqf0lp/9zzL3An8Gl6wPIcXG+r0cmXZFeBFwOuAFeB/AC/SWi/jHf/r8LzTDF787rX+ep8G3o4XPC8AnwH6/LjhT+N5XMvA3wG/0hGD/ge8NzyDl6i5mfV5PXAfXkwqg1de5crmHgOt9Z/jeZrvxDN+38HzXJ57IfFzP8b/W3gXzDm8c7uIdwHeKK8HXupv44PAJzexDcfjxLcXvwG8By/B/jBe0gz/+/rz/v+rwC9yjrtrrXULz5nah5fIn/aXB/gqXhJwXikloa7/6e/riPIqbr4MHPC39UW8JN1X/WW+enFebTtuLH0HSqmP4mVV33i+ZR1bjx8iyuKFEU5v8eE4HBvCeWuOKw6l1E8ppeJ+6OmdeHchZ7b2qByOjeMMsONK5Gfwwk6zwFXAL2l3K+e4AnEhCIfD4dginAfscDgcW4QzwI6nDMrT/3BKaU9BLtdzf1kYYGWJqTie2qgLkDbdokNzXGKeiuf+sjDADkcHF13a1HHF8JQ695eVAVaetOQ3lVLvVp4s3YTf8fQKpdRZpdSiUupXreVfqJT6T+VJWp5VSr2lY3uPJVvYpZT6PeVJYa4opT6llOp7gl+yY33OJ216zvPudz/d6p/TrPLkS7d17kApNaKUulcp9fpL+UIcG+Ypde4vKwPs80zgXrz+/n/A63h6Bl53y8uA96hHVPVLeCerB3gh8Bql1M8CKKUO4XW53YynE9FNu+DOb+NJHj4LT3hjFU9e0rH1HAHSytNtDuB1M91qPX/O8473he3G6+PvB16N1/Nv8G9l7wDeo7V+5yV7FY7N8JQ695ejAT6ttf6I31b4Sbw3821a65rW+ktAHc8Yo7X+mtb6Pl+28F48PVmREzyfbOH/DbxBaz3tt8C+BXixeoor9F9GnFPa9DznvYH35dvnSxse1Vrnre0ewtNwfrPW+gNPwOtwbJynzLm/HI3NgvV3BUBr3fmYyAk+E/gzPNHkMJ6A86f95c4nW7gT+BellC1L2cITgD+XjrHjieOc0qbnOe+fwLto/5Py5szdinehbfjP34zX2//Pl/j4HZvnKXPuL0cPeCP8A56i/bjWuhtv7IgoY51PtvAs8BMdEnhR7Y1OcWwx55E2Ped590W736q1PoQ3oeRFtMcU34InwvQP/i2u4zLjqXTur3QDnAIyWuuqUuoGPGUr4Xyyhe8D3q78eW9KqUGl1M88UQfuuCDOJW16zvOulHq2Uuoa/wuWx7stbVnrNvDGVSWATyg39PVy5Slx7rf8AB4nrwXeppQq4MV4PyVPXIBs4V/jXUm/5K9/BC8B6LhMeAxp03Oed2AY7+Kbx5vxdgftSRxb4nAI+PDl8EV0tPNUOfdPGS0IJ1vocDguN57UV34nW+hwOC5nntQGGCdb6HA4LmOeMiEIh8PhuNx4snvADofDcdniDLDD4XBsERvqhIvFYjqdTiNhi87whf14599ra2torVFK0dXVhVLqUevK861Wy/wty3dur9lsopQiEAgQDAYJBoPEYjHC4TDBYJBAIEAgEDDryLbsn80g2+pEKWWO0d6+vPbJyUkymcxmx6dvOUopF6t6fCxrrQe3+iA2izv/j5t1z/+GDHA6neYXfuEXWFtbo9VqUa/XjdFptVq0Wi2azSb1eh1oN5aNRgOlFNFolGg0SjAYpF6vs7bmdQKHQiFCoRBra2tks1nK5TLNZpNwOAzA2toajUbDrLO2tkY6naa7u5vu7m6SySQ7d+5keHiYgYEB+vr6SCQSFAoFqtWqMdCJRIL+/n4ikYi5EIiRt+nq6jLHJn/bFxbAGFm5YLRaXs13JBIhHA6jtaZer1OpVHjuc5+7kbfa8eRjcqsPwLGlrHv+N2SAtdY0Gg1jgGu1mjGG8iNGRxDDFggECIVCxGIxYrEYwaC367W1NcLhMNFolEgkQq1Wo1KpUK/XabVarK2t0Ww2qdVqNJtNms0mWmtisRjxeJxEIkE0GqXZbDI7O0uj0aBYLJLNZolGoywuLlIqlQiFQiSTSQYGBozxFiMMEA6HjUGV32tra22G2D4e++LRaDSMce7q6iIejxOJRMwFo1arPepuweFwODZkgNfW1ozX22q1qFarNBqNNu8xEAiwtraGUopQKGQMbavVMkZYfmQ9Mb6tVotsNkulUqHZbNLV1UUwGKTVatHV1UUgEDDrNJtNyuUykUgEgFwux8rKCj09PcYoB4NBpqenaTQahEIhUqkUQ0NDXH/99Rw+fJi+vj6zvhyr7CcSibC2tmZeT6PRoFKpUKlUyOfz5HI5isUitVqNYDBo9hmNRonH4wQCASqVinmPms3m4z9bDofjScWGPeBSqWS8vVarZeKwQjgcpquri1gsRjKZJBqN0mq1KJfLrK2tEQwGCYfDBAIBY7BiMU/wfmlpiXw+b4wvYIyiGEQx7uJRijHM5/OUy2XC4bAJXwSDQeLxOMlkkmazSaFQYHl5mWazSSAQYHx8nGQySblcJp/P02g0TKhiYGCAaDRKKBSi1WqRyWR44IEHzDFWq1Wq1Sq5XI5gMMj27dsZGxtjcHCQRCJBrVZjeXm57cfhcDhsNmyABYnnVqvVtmWUUgwODpJMJgmFQubxSCRCMBgkEokQiURQSlGtVgmHw6ytrVGr1ajValSrVXOrLx6vxJEB46ECJhwht/6BQMAY12AwSCgUIpFIEAqFaDQ8RbpGo8Hk5CTbtm0jHA5Tr9eZmJggl8uRyWSo1Woopejp6WHHjh0MDQ1RqVSYnp7m6NGjrKysmG3JMQQCAer1OplMxni/9Xqd1dVVisUizWbThCscDodD2LAe8HoVABIrFYOXTCZNkk282Xg8Tk9PD/F43CTbCoUCWmuq1aoxvrVazSTslFJtiTAxthJSCIfDJs4KnpEXQy1x5a6uLhO3luMol8vMz8+buPDExATVatUk/1qtFolEgmw2S3d3tzGuKysrxoOX1y2e8PLyMqurq6b6otVqUalUiMVi9Pf3E41GN32SHA7Hk5NNGWAprbITbxJWEG+zVCqZWG4qlaKvr4/e3l7i8ThKKer1uvmxKyUkwSUVCnY4QkrU5HnZlxjdUChErVYz3nA8HjdGUgxwNBqlXq+zsrJivN3FxUXC4bC5AEjlgsS3Jfa9trbG+Pg40WjUXDhyuRwLCwsmHtxsNo3h7+rqYmhoiH379nH33Xdf3DPncDiueB5XEq7RaFCr1QiFQsYwVyoVCoUClUqFrq4ukskkvb29DA4O0tPTQyAQoNFoGEMq9bzhcJhkMmmeF087EAiYbct+xQuWBJkYOzm2UChEPB43Xrgcq1wgAIrFIqurq8bjHh8fp6+vr63cTSlFqVQyxxiPx9m/fz+9vb2sra1RLBaZnZ2lUqmY5ezKiXQ6za5du7j22mv53Oc+d/HPnsPhuKLZcAxYPEExamJwwTPQpVKJarVKKpViYGCAgYEBdu/ezejoqPF85XZ/aWmprVYYIBaLtYUuxLA2m01TZyu3+RJ/lnKyrq4uSqUStVrNJOTs5xuNhjlW2afEcOV5u/EjFArR3d1NrVYjn89z+vRpTp8+TaVSobu7m1gsxujoKJlMhkwmQ7FYNBclqYyQ6giHw+HoZMMhCLsO2I6Baq1N+dbw8DAjIyP09/eb+OfS0hJKKWq1GsVikfn5eTKZDIAJY4BnLKWu1zaadiddNBpl27ZtJBIJE+4olUqsra3R29trknB2lYaEJYrFoilvk/riarVKuVw22xcPW4xzsVikWCwSDAaZnZ1lbm6OZDJJX18fg4ODxGIxU0on70MikWDbtm0mIbnZzjuHw/HkZcMesBhfCSFItUIsFqOnp4eBgQG2b99OKpUyMdypqSlThlav1ymXy6Z0zC43k5pcMZqSyCqXy+YYJLY7OjrK8PAwWmuy2SwTExNks1mSyaTZT6PRMHFcCT0opSgUCqZdOR6Pm/hzMBg0r1GMtnT32YnBZrNpPP94PE6r1SISiRCLxejq6qKnp4fdu3dz9dVXs2PHDlKp1MU6Xw6H40nEhg2w3XJsVzgMDAywbds2xsbG2LZtm6kcWFhYYG5ujkwmY9aRGGu1WjVxWalaSCQSbXHmUqlk/g8EAoTDYVNZMDIyQjAYJJ1Os7Ky0mYQpYJCjLeUqonxjMVipFIpksmkaQKxS8XEi5YEnnjHUuEh3j54Fw+70mF0dJTDhw9z1VVX0dfXRzwev1jny+FwPInYsAGu1WrGAGutTTigr6+PVCpFtVrlwQcfZH5+npWVFTKZDKurq5RKpUfpLcAjdb0SFhBPVZJvUnNbr9fp7e01Rh68Jgwxkl1dXaaWWDQfQqGQiRU3m01KpRKZTIZUKsXo6Cjj4+MMDAxQqVQ4cuQI+Xy+LYknMWuJTweDQQYGBtixY0dbXLdcLrfdBUhDhnQBOhwOx3psyEK0Wi2KxaLxgsEr/crn86bhoFAoUCwWKZVKJgQgVQ/iVUojhYQKQqEQkUjENFKIUY5Go4yNjdFsNpmZmWFkZIRrrrmGHTt2AJDNZo02QyKRoK+vz9TqptNphoaG2L59O7lcjmq1asrD1tbWTAhBwgUrKyvcf//9JhYMnmHNZDIm1NLV1UUul0NrTTweNzXNEoLo6emhp6eHVCplSuLEq3ZaEA6Ho5MNl6EVi8U2ZTBpimg2m1SrVSqViikPk9t6qSqQBJeECIA2g1ypVKjVagwMDDA+Ps7evXs5ePAgi4uLHDlyhF27dnHgwAF27Nhhkm+2cRwZGWFhYYFCoUCpVGJmZoZQKES5XKZcLhtRHAmFSO1yoVBgaWnJJBMldFEsFtsqLaLRqEkiJpNJU+UgNcOSoBT1NfH4nfF1OBzrseEQRKVSMX/L/5Iwk5rbQCDQpo0rTRXBYLCtphceUSETjYfBwUGuvvpqDh06xMGDB9m1axf33HMP6XSa/v5+tm/fzvbt29saOWSfAwMDjIyMsLq6ytLSEhMTE5TLZeOBB4NBotGoSaQ1Gg2y2SzZbJbFxcW22LMYYVFrSyQS9Pb2mm4+Mb6xWMx4/rJ9wDRrOBwOx7nYsAdcrVbbxMal80yMje39dpaAScOGXUlha+3G43EOHTrEjTfeyNVXX82uXbuIx+NMTEyQTqdN2Vd/f7+RgLS3I00V0p0WCASYmZkBMDHhVCpFMBikUCgYr1UaKeRYJDQCGDGf3t5eRkZGGBkZYXBwkL6+Pnp6eohEIqYjTiopZD27fdoZY4fD0cmGs0S2AI4YKmmCEGMrt97iFQeDQZLJJPDIRIlIJGKaNsAzWDt37uRFL3oRN9xwg0l0zc3NEQ6H2bNnD+Pj48boSZJO9id1vc1mk97eXvr7+9m2bRunT59mZWXFKLGJZ7q0tEQ2m6VYLFKv1038WTzjRqNBLBYzXq9dYjc2NmaqJ4LBILVajbm5Obq6uiiXy+zevdsowUnIwxlgh8PRyYY9YDtJJd6sxHHtCROi2yDGR7xeMYKpVMpUCqytrRGLxdi7dy9XX301qVTK1AtPTU1Rr9e56aabGBoaoru721RHdHrXYojtx9LpNIVCoa0uuFgsmlpiOX65MIg33Gg0jLavNFrEYjH6+voYGBgw4RTx+EWistVqGQU1Mb7lcrlNpN7hcDhgEx6whBEkDGEbWMDEUe05cFLaJa3Jo6OjXHXVVYyOjhKJRFhZWWFhYYFSqcRDDz1ktHml4mLnzp2mzlZafRuNhkmiiZylLQ4vseVEIkFPT09b84iEH+SYJWYtIQ3xhO3XKlUZIrMp1ReNRsPUCksislAoUC6XKZVKrK6uMjs7a1qgHQ6HQ9iwAZZbfvF+7Rhnp1i6tA2nUikOHTrEvn372LlzJ2NjYyac0NXVxerqKgsLC8zPz5NKpYwhDIVC9PT0kE6nTQmZGEcRzQHM/xLusMMgXV1dbeOGpGRManvt8UN2bFq64WwNCgk5SGxXDH8+nzfhlGg0SqVSIZvNsrKywuzsLFNTUyZ56XA4HMKm5Cjlxx5ECTxq2rF0iw0ODnL99ddzww03sGvXLgYHB9sMrTRYDA8Pm8kXiUTCqKnZouz20E/RchDNCDHAneOFxIOVTjo5djHUYmTFo7UnNMv25fXYr7HZbJLL5Zifn2dpaclcEDKZDK1Wi4mJCaanp1lcXGwTcXc4HA7YhAG2hXPs8fHynMSD5blAIEB/fz8HDhxg//79DA0NmYkYUr2QSqVIpVLEYjETGrA9zEAgQKlUMt6p1NnamsQSgrDnzonWg8SG7Qkb0WjUhDAEEd+xwyeCnWSU+udCocCZM2e45557OHnyJM1mk56eHhMeOXXqlKmbdmI8j5+NvIfrTa9e7zmHYyt5XFUQ8kG2f4uxsT3PaDRquuAkCWe3DtsTLUKhkBlkKdsVo1etVimVShQKBWq1mmnEkHCF3dJsi7dHIhFTuytdapJgEwUz8YjtL6scl3jPXV1dplljdXWVM2fO8O1vf5vjx48bg726uko+nzeGX8rf5ubmHt+ZeooguhxS222L8tuxeqDtb2ifmnIuI2vfvYnzYE9ecTieSDYVA7Y/5HZNMGC0HOxhmhLHjcVixusUPeFCoWC0GkS1zC5jk1pjkY3M5XJMTk5y+vRpM3hTDK7dCFGr1UwoQMTeRaehu7ubeDxuvGAxyPKll5/OL7pUgczNzTE1NcXJkyd56KGHKJVKpFIpE4eWmHR3d/ejvGzHYyO11DJXz54BCJBKpdo+J2KgFxYWzP9yruxpKoLUeneGkuzPtcPxRLFptRg7FiwfehlFL96ETLro6+szVQz2mPdqtdqmGyHz1uyQhjRK5PN5k9ian5+nXq8Ti8VMOEOeF2Ncr9dZXl42HmipVDL7CofD9Pb20t3dTXd3twl/yBdbtmEP05TE3NmzZ3nggQeYnJxkbm6ORqNhxNmr1aoxGqLuFg6H3Zd6g0hs3n7ftNYkEgme+cxn8qxnPcucd4Bqtcqb3/zmthb3x3rPbaNst8i783R5MzY2xqte9apNr99qtXj729/elrfaajZsgB/r1q6zCUOGdA4MDNDf328mVIj3K63E4uHalQqyrbW1NRYWFszQSxFnHx0dpa+vr0305uzZs2Zd8DybeDxujLo0TFQqFXp6ehgaGmLbtm0MDQ2Z6giphJAEodQIS4Lu+PHjRu2tVCoRj8dJp9MmDq21Nx9PmkUe6z1zPBo7BCRe6sGDB0kmk/T39/PCF76Ql7/85aalXEJTX/ziFx81oXu9O7Suri6OHz/epmlyIUbbsXUcPnyYRCLB4cOHedOb3rTp7TQaDb7yla/QaDSYnp5mdnb2Ih7l5tiUAe78oNp1wXYSLR6PMzQ0xOjoKOl02oQe5HkZkikGL5vNGiOrlCIWixEMBjl16hSLi4sAdHd3G7HzeDxuxhtFo1GWl5fJZrNEIhGSySSpVIpdu3YRiURM/e/i4iLlcpmlpSUTT15bWyMajRrvXaZh2BrC+Xyeqakpjh49ao4vkUiYLr98Pm9mx6XTaRPLtt83x2MjFyyp5xZt5w9/+MNcf/31AEb4yE6qRqNRvvSlL7UNb7XjxXZuoquri2c/+9ncddddpqrG3reLBV9ehMNhPv7xj5vz/3gIhUJ84xvfAOBtb3sbb3/72wG2tElqU4LsdnOCeKm2ARbju2PHDq699lr27t1r9HUlMVapVIzhk9jqysoKDz/8MNlsFq218T7r9brR4d21axd79uyhv7/fJMVyuZwRWC8Wi6b6ob+/n3Q6bRJ+5XKZQqFAoVBgfn6eubk5stksZ86cMTXJ8oW0a5ozmQxTU1Pcf//9pqRMkodKKc6cOWNi0PF43MSD5TXatdGOc2OHsaS1/B3veAfj4+PGiIZCIWKxWFu4wV4XMPFfW+jJjue/+93v5hOf+ASf/vSnjRck591x+RAOh1lZWSGRSFz0bb/hDW/g93//96nVavT19W1Zmeim6oDtRJXU4MpzQjKZZNu2bUb0HB4ZhFmr1ahUKrRaLWq1GktLS0xOTnLvvfcyPT3dJuQTCATYtWsX+/fvZ2xsjKGhIdLpdNuctXq9Tk9Pj5HFBC8J2NPTY0YUiQGWxhCJR8/MzJDNZjlx4gR79uwxYj1CNptlamqKEydOcOzYMfM6petNLkbd3d3Gi5ZSOVsDwhngC0M+I4lEghtvvJEbbrjBfAHtJiBB3n87ZmxXwsj/sm2lFFdddRVPf/rTOX36NA899BAnT550SbjLjMOHD/Pxj3+cRCJxSUo4OxPtW8WGDbBtfO3khdyui1Hu7u42MdZEItGWmRZNBhlZNDs7y+TkJKdOnWJpaQnAVC7s3LnTGHFJltnC6mKopWtOqjDk1jQcDrcpp4GnjCZZ9kqlwurqKvPz8wwODhrDLCOTlpaWePjhhzlz5oz5Atsi8xLnjkQiJu7bmTxyXBh2BcPAwAC33HILe/bsaUvswiP15sJ6usvrGWn5OxKJ8H3f933U63WSySSTk5NtM/+cId5anv3sZ3PzzTdflLDD+QgEArzpTW/ive9975bEhDdkgMXTsBsS7JgueIZTqgxEOlKMonSxSfXD5OQkDz/8MPPz8ywsLLC0tESxWAQwnqq0LScSCcLhsCk7k2YIMfz2OnYbsq33IEnAcDhsxt0XCgUmJyfJZDLGKwcvlLK6usrZs2eZnp42Az+l5Vi+sDKjzva4JBwhMWF5zHHh9Pb28rM/+7PGI5bPlzTerMeFvsdaa/bu3WuEmr7zne8wPT1tQkp2ZYTjieXw4cPcfPPNvPKVr3xC9hcIBHjjG9/IZz7zmcvfAAOPMrpSQ2mXpInS2LZt20in06YyQcYVZTIZzpw5w3e/+11Onjxpmhvi8bhJ1CWTSZPAk3ZkMWwyrdhGJnPYhlZrTzBe1pVb03g8bsbWl8tlBgcHTXVEtVo1Hlc+n2d5eRmAdDpttifHKw0eMpxTQidS+2sneRznR+4o7A5H8Ygl6SYC+XL+15sz2Int0cpnUZKo11xzDS972cv40Ic+5JplLgM+9rGP8fSnP32rD+MJY0MGWBor7PIdux5Tlunu7mZsbIx0Om1kJbXW5PN5VldXmZmZ4Vvf+hbf+973WFlZIRKJkEqlTLNGNBolnU4zPDxs9HYDgYBRSINHBM9t5bJqtcrq6iqRSMQ0WEh9r8Sby+WyqfdNpVIMDQ2xe/duTp48aUISEkrIZDLMzs6acIY0jQQCATOSSLx7+4IgZWgSJ7briR2PjdxZyPgre7QTYGq8RanuQlmvwzEej3PDDTdwww038OUvf5mVlRUnG+p4QtlwFURnK7IdlpBSnsHBQUZHR0mlUoBXOrS8vMzy8jJTU1NMTExw8uRJKpWKCSsAxrDJwMtwOGzG/YgRs2uIxfhprUkmk6YeWIyhPW/OVnArFAomjCLTLkQcSIyzNH/Y3VLFYtGUx4ngumDHL6Uhw86suhDE+bETaSdOnOAFL3gB4F3cXvrSl/Lyl7+c3t5egEd1s50LuylIzpF8buRxCWe5u5Wt52Uvexmve93ruOWWW7b6UJ4QNmyAO4VlJM5phwd6e3vNmHqZErG4uMjZs2c5fvw4ExMTRi9BPFQJHUgcVwxxs9mkUqmYfYgBtj3VYDBIJBIxX+BOkXY5bnkNkkQT0R7xmMVgS01yNps1+6xUKlQqFRPCkBInu7VVQjPiRZ1LY8KxPlprc8Esl8scPXrUXOTD4TBnz54llUqhlOKWW25hZGSkLQewHnb9r5wDu7VZEsNSi+7YWo4dO8att97K2bNnCQQCvOENb3hCWvlf/epXc+utt3LHHXdc8n3ZbNgA216veMQSr5MviqibSbdSqVRiaWmJqakppqammJubIxKJMDQ0ZOpvRX9XBHPS6bSRpOzU/pW/xXBGIhHTFCGeuK0RYV8k7GOGR8rq7OWljTmXy5nQh0xsTiaTj0q4CXZHlRhj2b4zwOdHjKlcMO0475EjRzhy5Ij5jF177bX80A/9ED09PcZwd1afPNY5spNstgSpM8Jbzx133MEdd9xBKBTiOc95jsnpJJNJDh06dEn2+QM/8AMcOXLk8jbA0P4BlmoEO/6ZSqXo7u429cEStxUPuFAoEI1GjaGV0jEpwBfRnFQq1RbnlfHzYjwlNCEGuFarEYvFjFdtf8HsWlGgzQDbGW+pUW42m6yurlIqlcwtr7Qli6dr6xWIkQZMOEXaku0SKMf5WS8GayfhRHL0Xe96F7lcjhe/+MU0m02T7JXzLEJNdoLYRoyt7fnaDoarhNh6Go0GN954o/n/+7//+/nmN78JsOEcwPl4xStewdGjRy/a9i6UDZehdSbcbBlIue0PBoOUSiVjKHO5HDMzM1SrVdLpNIODg6bVNJFImEoCCT/09PSQSCSIRqMEg0Hy+Tz5fN54yWL4pKFDLgTg3V7WajWi0aiJ0Ur1g63tYNcll8tlM4JeEm3z8/N0dXVRKpXMfDeJ+9ots4AJO9hfVjuL75Jwjw8JA8n5K5fL3HnnnUxMTPBv//ZvfOQjHzFGWi7WnSpqNjKEVcSf7M+xa565fDl69KgZ7nvkyJEnpE74UnP+Gh4LafEVWUm7M8lWOBOjUy6XTbPF3Nwc9XqdaDRKd3e36Wbr7u42gy57e3tN6EE85L6+PoaGhujv7zeqY/Donn2phhCdYDGknUlCuUBIfLher5PNZo3HVCwWmZmZoVAo0N/fbxTUxADLa5d9SsINaAs32HXS0rTh2BzSli5awVJGmMvl+OY3v8krXvGKtti7xPPPdQfSGWoQCVE7nuyM7+WHnb+5+eab+dCHPrTVh/S42VQjhnh3YlhsERS7XlPqbDOZDNlsFsCMahftXtFOkG6yWCzW9iOlXnZ1gcxXE8NvtzfbM9xkG4LIRMrkDdEYLhQKhEIhGo0G+XyeQqFgvCL5ckqbsdSg2reuEosWj0uSdnbtqePiIZ8tpRTZbJYjR45w5513snfvXhP+gvawkY38X61WWV5e5uTJk6a80c4VOC5fjh07dlmomT1eNtWIIQbYrsGV2zmpTJAZa/aU4GAwaMqzJEQgcVvxeOPxuNleNBo1gzBFAUu61cQQ2vKRQFs8VkrL7NieTDYuFAqUSiUzvTgWixlvt9lsGsGXTq/KLjcTj8meliytyoCZ1uF4/NhJU4mvS1gpk8lw22238bKXvYxYLGbOgx1qsnMXkrArl8scO3aML3zhC20lh44rg5mZGR588MFLlph7ItiQAZbbPPESbI9PyrlEZ0G81XK5bMrI7DZSkYuUkEYymWwrXbNL28RwwiPZazGOjUaDcrkMYBI0MkhTEmqynhhL+fLV63WKxSKNRoNUKmX0hCUmPTExYWKLdtOHaBhLN5xM1JBSOLnodM6Vc2wOMZhSzSKfIYmtV6tV3vOe93DDDTcwMjJCKpVqE1vp1P2Vz1e5XOZb3/oWH/jAB9zQ1CuQD3zgA9x9991885vfNGHBzdCZv3ki2bAB7hyvLl8I8UalckHadldWVpiZmSGXyxGNRk2nk10BIQkRqYLoLEWSUUHiCUshvVwARF9Ca29qglRBSCjAjlmL516tVslkMiwtLdFqtRgYGDAGWIx0JpMx5XQi7GOPrxdjLDKXQqvVolgstjVkuCTc5rHvItZLdNr1vXb4QT434gnLnZncMa2trZmZgPbn2HHlcPToUfr7+8lkMm0NNhdKvV6nr6/POHFPNBuOAUt8184Ud5Z5yQe+VqtRKBRYXV2lVqu1GTA7QWUXwovnYpeJSWmXXVEg+5JYdLlcNvFdWa5QKJiEjV2pIUI7CwsLxsg++OCDAOYCsLi4SCQSIZ1Om3ZrSTrKtiTmnM/nzXQP8ZLFG7dfr+PSIJ+3YrFoyhwl4ZrNZs3dWalUIhKJsLq6ym233canPvUpTp06ZaZs2/FfFwe+MtBaP+728SvGA4ZH6lzhkcoDoM1j7Sy7kgzzuZ6HR0IEdqxOPGHb+MlFQJJedrhCjGC1WjVeaSwWM0ZXuteWlpaYnZ2lVCqZxFo2myUejxvtYIkLi+crX0jpxCoWi3R1dbG6ukqxWGxrSLEFX85Vh+q4eMiF7rOf/SwLCwtcd911/PAP/7Bp2pAQkhjZv//7v+fzn/88//mf/0mpVGrzkjuTcM4IX/60Wi3e+ta38trXvpbR0dELXm96epr3ve99W3rXsyk9YFu82taGsJHGCknKdXaJAcablC40e7lOj9ouJ7O1fiXxJxKRpVLJLCuJPInVShx3cnLS6A6n0+m20UHlcplisUi9Xqe3t9eI+sixpFIpY/xFaEfCKlI5Idiqcc4AXxrsxosvfOELzM/Ps7a2xk033YRSymhRiwbEsWPH+MQnPsGDDz5okqiyvvN8r0xk2ObP/dzPXbABnp6e5vbbbzdjibaKDYcgJIbaGVez62wlFNBqtUyjRS6XM56IGHCJ+Up9rXginX37tpYDYKoOZCyQeL25XM48JnW9MjdOytey2Sy5XI5wOGwmddx111309fWRy+VYWloim83S3d1twhGSaJOROKKsJombZDJplpHjrlarxkDDhckmOjaOXNCl+qTZbBIIBIjFYua9l89EIBDgNa95DZOTk2ZdyRVIfkCcA2eErzyk6uh82hGNRoO/+7u/40//9E+foCM7NxtOwtnlQOIBy/9ihEUnd21tzYjqSDJK6m+l88z2fuU5u+TL9k5sj0UmUEiCTDzSQqFg4rq1Wo1MJmMaLFZXV8nn8+zZs4fe3l6y2Sxnz55lZWXFSFlWq1WjZyHeu61HIfFsqZwYGRmhr6+PYrHIysoKmUzGyG9K80AwGHRas5eQzrCBNAR1dXVRLBa59dZb+eQnPwnA/fff31bxYJdVOqN7ZXPTTTfx5je/mTe+8Y3nXe7OO+98go7qsdlUK7IYRzubDN6tQKFQaLsSRSIRMy/N7lJbXV0lm822GTqp9RVPc73JG7YkpYQcstmsaX22dX9luKeMN+rp6WH79u309PSwtLTEiRMnmJqaMloS0tYssV+JEctztVqNSCTCzp072bZtGz09PcbwnzhxwgjOh8NhU14n5WkTExOX5AQ+1bFDW+DdeczOzvIf//EfphLnyJEjfO973wMe6XqzQ0PO8D45aDabvPe97+Xhhx/mox/9qHn8/e9/Px/84AfN/w899NBlU5W04RgwPFIUb4+gt6cdi7aCUt50DGkzXl1dNbW3q6urLC0tmbphMehijCU2LPuzKwzsRFk+nzfj7CUZJt64rS3R29trRH4WFhY4duyYGXUPsLq6SqPRMFrE0l1Xq9UArxFjZGSEkZERtm/fTl9fH5FIhHw+b0YadXV1MTAwYFTcpClAvHbHpUOM6MLCAt/+9rdZWloiGAxSrVZ56KGHKJVKbW3zLsn25GR2dpbbb7+dN7/5zeaxr33ta1sitHMhbLoTzg4/yGMSQhBPUOK/27ZtY2RkhHK5bKQd8/k8S0tLpoNMevftxJp4N3JLWalUjCpasVgkn8+Ty+XIZrNkMhmjNSHtzX19fYyNjZnBoNJJd/bsWSYmJlBKkUwmaTQaZLNZk6iT4n7AxLGHh4c5dOgQe/bsMRrG4n2fPn2aUqlk9plIJIxgvMTMHZcerbUJA917771EIhEjNWmHKZzRfXIzOzvL2972tq0+jAtiw3rAwKOqFezAt2jpDg0NmSaG0dFRcrkcuVyO5eVlI9QjhlMaJSSpZ7cga60plUpm/WKxyNramtEYlrhuPp8nFAoxMDDAtm3b6O/vp6enh4GBAeLxOOBVOJw8eZK7777bJMxKpRJzc3PG+xXDHgwGOXjwIHv37mV0dJShoSHj3RaLRZaWlpienua+++6jWCzS39/P4OAgPT09be2yTgnt0tJpTO1yM/siKA0YDsflxIZjwFJZIB1E1WqVfD5v4rKi/Xvw4EFisRg9PT309fW11c4uLy9TrVYplUqsrKyY+G88HmdwcNA0Voh3LII+y8vLJslVLpdNHFm0e0VTYnBw0CTHenp6AJifn+fUqVPcf//99PT0UK1WzboSK9yxYwc7d+5k+/btjI+PMzw8zODgoJl6LJ735OQkDz74IBMTE2SzWYaGhhgaGiIcDpsEjyQGRbfChSAuHXYeQgxyKBQyYSR5zJ0Dx+XGhkMQYmjF4xXJx1arRbVapdVqsbKyYrzggYEBEz/dtWsX5XLZGO18Pm+Mby6XIxKJsLy8bETd0+m0mXggspYyul5iyfl83njF/f39jIyM0N/fb8YGVatV5ubmmJiY4MyZM2bAZ71eJxKJMD4+TjqdJp1Os3v3bgYHB0282BbYkVvXubk5jh07xtzcHGtra4yPj5uYr3TUSKeeePK2Uprj4mOXLiql2qam2FrRdsLOhSEclwObSsKJloJ4wJ3KU8VikeXlZbLZLP39/Wb22tDQEIVCgUajwczMDPV6nZWVFSqViokXl8vltokZfX19BAIBcrmckbUUAyxi6c1mk1Qqxfj4OCMjI3R3d5uQxtTUFNPT08zPz5sqh2w2SzAYZHh42Fwkent7GRwcNELwEg+2tY4rlQonT55kYWGBZrNpBIUk2SPxRpmaIXKI4kE7Lg22Me1Uv+t83lU9OC4nNlWGJsZFEkzi3Undbq1WY3l5mYWFBSO4EwwG6evrM8sHAgHm5uaMKpndLCH1s/F4nGw2SyAQMOI2Uv1QKpWM2lk4HGZoaIidO3fS399PNBo1F4KTJ0+yuLjYllQrl8uMjY2xb98+UxMs2sF2C7HEDGWd2dlZk3ATYXlJ9Nht2fYwUJlz5wzwpWU9r9buunQ4Lkc2lYQTbG1VaRNWSlGtVllcXDQlZgCjo6Pmtn5gYIDBwUGOHz9u5sTV63WTSJPmDCkxA9pkMCuVCrlcDvDE0Ht7e9m7dy+7d+82ugC1Wo3JyUlOnDhhytvEI04mk1xzzTUcOHCA0dFRksmkEQ+Si4u0FYu8ZCaT4e677zZiL1LSZndfAaZJRDx4+dmMUpPD4Xhys6mhnHa4ATCz2iTU0Gq1WFxcNMI7kUiEnp4eUyIWi8VIp9OMjIwwNTXFxMQEMzMz5PN5wIsrSwJLxtqLDKbM/Wo2mwwODjI8PMz27dvZvXu3aZ4olUrMzs7y9a9/HcA8Xi6XqdVqPP/5z+eaa66hv7/fhA+AtguJxH7F+J4+fZp77rmH/fv309/fb2KNckySaJMk5eDgoBmhFI1GXQLI4XA8ik3VAYvxlRZhUSeTCRfS+lssFpmdnaWnp4eRkRETXw2Hw2YEkQjmpFIpJiYmTIxYQhydwxXF2+zp6WF0dJTx8XHT3QaY9uKzZ8+aduGVlRXT1Xbttdeyb98+0ul02yjzzokJAJVKxSTwJicn27xrwGgQ2BoXEsIQTQxJArlSNIfD0cmGQxCdYiWdEpEyZFM606rVKgsLC8zMzJBOp42XHAqFjFKVNHZIQ4RoKUj8NJFI0N3dbTztYDBIIpFgbGyM4eFh+vr6CIfDFAoF5ufnmZ2dZXl52cx0K5fLhEIhhoeHOXDgAP39/Y/SNRYP1RaDl2Ofnp5mZWWF7u5uUyIny4vxlZpfW0JTQjIu6+5wONZjU2Vo8IgnbCfgRIVqeHiYaDTK0tKSEcc5ffq0kXcUz1Bu13t6esxkA7uyAR5p+rBv4UUsR0YYifDPwsICs7OzLC0tUalUSCaTJoY8MDDAvn372L17N4lEwoQQZL+yH3vkTa1WM80ipVLJ1ChLiESMr2hUiLhQp7frhF4cDsd6bFoLwjYyYrykXAs8nV2JAWezWU6ePGlu+8VrTiQSrK2tEQ6H6evro6+vz6ifidiO7U3acoGS2JLlc7mciSVXq1Uj5lOpVBgcHOSqq67iaU97mrk42NoSMg5JQgq2DrE9gUOE2eGRkAU8WgbPLoOSagpngB0ORyebigHbEymkOkGU0AqFghkDI7WzUrXQ1dVFPp8nk8mwa9cuuru7Aa9sSzznZDJpRhTZhkuqDcSwyRiSVqtFqVTivvvu47vf/a4ZcQ+Qy+Xo7e3luuuu46qrrmJsbIxQKGQaRsS4SgOFxHDlQiKvR2tthHWktbWz9tSW5UwkEqbio9lsmknLDofDYbOpEIRtfOR/8TjBM3x2EXxXVxeNRsNMK5BR8ENDQyQSCdLptOnft1XQACO0LV6mdNxFo1EymQyzs7NMTExw7Ngxc/tfKpWMUtv111/PoUOH6O3tNZNwpbpCEIMvr0EuKNlslsXFRdMm3dnNZmtiSNItHo+TTqeN/oQ0jLh6VIfD0cmmhnLCI/339shwuVW3RxYJWnvD81ZXVwGMoRwcHAQwEy5qtRrRaLTNoANtHmY4HKZcLjM3N8eJEyeYmJggn88TjUYpl8smFj00NMTevXvp6+sjFAqZRJ/EamV7cjx2klGOVWLIsVjMePuAiWEDRsdYOvik8UJCHG4kkcPhWI8NG+BEItHWCSeiJ3brra3jKwZNYriVSsXc9stkiWAwSDqdNtUFUlcrtcCdxqvVarG8vMypU6eYmJhgcXHRaEo0m802+cjR0VGi0WjbfLbOOW12pYLEniuVCplMhkqlYtqaJflmK24JoVDITOeIRCLAI551ZxLR4XA4YIMGOBAIMDo6alpzZc6bbdTE6NqjfCSmak+0qFarpla41WoRjUbp7e1Fa22UxOz4rHjatVqN+fl57r77bh566CEKhYJpmsjn84yNjXHVVVdx4MAB9u3bZ5Jg63m4toCLGFQpP5NWaknSSbu01BvbFyDxymWAp2xDjK/oSjgcDofNhmPA0mghXqUYMnuKhWgqiMGrVCrGANshDKn7zWaz5PN5MzjRbmqQcIMk8mZmZjh69CgnTpwAvGoI8OLO+/fv5wd/8AcZGRkhnU4bNTTpogsEAqZWVwynlKPZDR/1ep3p6WmmpqbM65C4s1RCyAVCQiPyXsisO1FBk+25JJzD4ehkw0M5Raxckm920kwSbp0ese35itconXPd3d2kUikzHVlmxAHG65QZctPT0zz88MPce++9FAoFUqkUrVaLWCzGtddeyzOe8QyGhoaM7oJMz5CyM7kQ2IplUgecTqep1Wqsra2Zho7V1VUjChQKhYzEpbwW8Y5lX4CpehCPWC40LgnncDg62bQBFsMiSBxVPEF75pY9/NBuy1VKEYvF6O7uNoM7xQsVMe3V1VXuu+8+jh8/zsrKitERrlQqDAwMMDw8zMjICAcPHmRkZMQ0R0h5moQu7NDDmTNnyOVyJh4di8XYsWOHqV1eXV0lk8mY0jo73mvPp5PXItUXUqkh+hX2qHNngB0ORycbDkHIsE14xOOVv+XH9ixtWUZBDHI4HDajfGR0kCTT6vW60XU4evQo999/P/V63Xic8Xic4eHhtrFBkvQSw1ipVNoScLVajZWVFU6cOGH0IcQAl0olRkZG0FqbcEgkEiGTyZgLjWhA2CEFiR/b3j7Q5vl3Nq44HA4HbEILQm7hxYjaWgiyjJ2Ig0fqZWU9kWzctWsXhw4dYv/+/YyNjRnx9Xw+z8zMDBMTExw/fpxSqcSePXtMPLdWq3H48GGe8YxnMDo6SiKRMEZSEnVSXSFeaKFQYHp6mgceeIBcLmeU1Gq1GsVikbNnz5qR8sFgkIGBARqNhjHAjUbDlLrZ3XmdrdhSt+xmwTkcjvOxKTEeO4xgJ+A6479SZWCXqIk05e7du3nWs57FgQMHGBwcNMm0xcVF7rnnHk6dOsX8/LypmGg2m4RCIUZGRrj22mu57rrriEajNJtN6vU64XCYSqViDKF45rlcjpMnTzI7O0smk6FarRKLxahUKma5RCJhBoaK8I80UkjSzU4QSvxaEm22CI/d+SZqb/I+OBwOh82mWpEBU7IlBlcMjG2IxQhKMiyZTDI0NMSePXtMh5qEHprNJlNTUxw9epTp6WlKpZLxeNfW1ti+fbsZmrlr1y5isZiJw4pout1oIZ13x44dY2VlhUajYeqYA4GAafqQDjiJ4YoXm8vlmJ+fJxwOE4vFTE2yXAjkb/Hs5T2Q7XRqQDgtCIfD0cmGGzHsv+3ElPxvP2bX3yaTSXbs2MHu3bvZt28fe/fuNQM7C4UCKysrnD59mjNnzhhh9kAgQDweZ2BggKc97Wls377dCJ13ymJKvLlQKJDL5VhdXWVmZoapqSlTixuJRIyRtA2neOgiAiQaF/akC3lOtmXHdm1xdtmmPYjTqaE5HI712NREDPvv9cTG7bCDUopoNMrQ0JBpjti5cyeDg4Nm5Pzs7KwZnlksFtFam/KvVCrFgQMH2L9/P93d3aZ+V0q77J9Go8HS0hJnz55lbm6OTCZDvV6np6fHlJDJHDk7TGGXyYlHHY/H2/6v1+vGQ+4cgS7bsH9LR6BLwDkcjnOxYQ9YMv624e0sLZMQQDgcJp1OMzw8zK5du7j66qvNbLhgMMjCwgJzc3NMTk4yMzPD6uqqaaBIJpP09fVx8OBBDh482FbqJYM8peyrVquZGO7Zs2eZmZkxguzj4+N0d3cbo20nz2wxHXkNoVCIgYEBtm3bRqvVYmVlhVwuRz6fp1arEYlE2mLesq4dGxcvWcIWdojG4XA4BLWRW2Ol1BIweekO50nNTq314FYfxGZx5/5x487/U5t1z/+GDLDD4XA4Lh5OIcbhcDi2CGeAHQ6HY4twBtjhcDi2CGeAHQ6HY4twBtjhcDi2CGeAHQ6HY4twBtjhcDi2CGeAHQ6HY4twBtjhcDi2iP8fayTXMUdRac0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VisualizeImageAndMask(image = test_images[0], mask = test_masks[0], prediction_img = op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "675c2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras library import  for Saving and loading model and weights\n",
    "\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "# serialize model to JSON\n",
    "#  the keras model which is trained is defined as 'model' in this example\n",
    "model_json = model.to_json()\n",
    "\n",
    "\n",
    "with open(\"./model/unet.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"./model/unet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d662399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('./model/unet.json', 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./model/unet.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1eb0392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 258ms/step\n",
      "[  0. 255.]\n"
     ]
    }
   ],
   "source": [
    "# get the test set images\n",
    "test_images, test_masks = train_gen.__getitem__(100)\n",
    "predicted_masks = loaded_model.predict(test_images)\n",
    "# print(predicted_masks[0])\n",
    "op = np.zeros((64, 64))\n",
    "for i in range(0, len(predicted_masks[0])):\n",
    "    for j in range(0, len(predicted_masks[0])):\n",
    "#         print(predicted_masks[0][i][j][0])\n",
    "        if predicted_masks[0][i][j][0] > 0.15:\n",
    "            op[i][j] = 255\n",
    "        else:\n",
    "            op[i][j] = 0\n",
    "print(np.unique(op))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69eaba3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAACcCAYAAABBRnGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABFv0lEQVR4nO29eZxlZ1nv+31rz2PN1TV09Zzupju5MUGCU4KAIAqOB1EJKErkAh49V+Gco4JMiooi6BFlPIxxALyRAwhKgEtkahI6how9pKu7qmsedu153vXeP9Z63rx7pzrdVelOdSfv9/OpT1Xtvaa9197PetYz/B6ltcbhcDgcTzxdW30ADofD8VTFGWCHw+HYIpwBdjgcji3CGWCHw+HYIpwBdjgcji3CGWCHw+HYIpwBvkJRSr1FKbW81cdxMVFKhZRSf6aUmlFKFZRS31FKvegC192llNL+zw+v8/wf+s+ducjHLPs973Eqpf5GKfWRDWz7X5VSf/j4jtBxOeMMsONy4n8C/w34E+DFwFeB79/gNorAL6/z+C/6z20JSqlx4BbgHRtY7c+A31VK9VySg3JsOc4AOy4nfgb4R63132qt/11r/fta67dscBufA16slArIA0qpa4CnAZ+/eIe6YV4N3K21PnahK2itvw6sAC+/ZEfl2FKcAX6SoJT6Uf9W+LlKqf+jlCoppU4qpZ6vlAoopf5CKbXs397/bse6P6iU+qxSatZf7x6l1M3n2Me9SqmqUuoupdQN/jbf0rHczyilvusvN6+U+nOlVOgCXkYL2Pe43gj4P0AKeLb12C8B3wBmOo4zoZR6j1LquFKqrJQ6rZT6W6VUumO5VyqlHlBKVfzXe4dS6vC5DsB/nwpKqT+xHv4V4J87ljuslPo3pVTGf98fUkr9Zsfm/l9/XceTEGeAn3y8H8/Y/Bwwifelfw+eUXqp//9fKqV+wFpnJ/BNvFvkn8L70n9EKWVu5ZVSY8AXgEW88MD7gb8HYvbOlVIvAW4D7gR+Gngr8CrgTy/g2P8BuFEp9ZoNveJ2Snierh2G+CXgH9dZNg4EgDcAPwH8IfAc4NOygFLqJuB9wK3+Mr8OfAvoXm/nSqkfx3uf/kJr/Qf+YweA7f56Np/Fu+i8DO+9+hu882TzLeDpSqnex3jNjisVrbX7uQJ/gLcAy9b/Pwpo4M3WY4f8x75qPdYFzAPvOMd2FRDEM7D2en8BLAMx67GX+Nt/i7XuJPCRjm3+OlAB+h/j9YTwDPrDQBN40Qbfj13+sbwI7+KTAcLADUADGADeCZx5jG0EgR/2t7PDf+z1wNEL3O9PA1Xg9R3LvNRfJmE9NuA/ds0Fvq7nbfVnzv1c/B/nAT/5+Ir198P+76/KA1rrNWACGJPHlFK9Sqn/pZSaxDNWDTyvdb+1rWcAt2utK9Zjn+3Y935gB/AppVRQfvz9R4GrH+O4/xi41l/mQ8AnbS/dDwG88zHWt/kCnmf743je71e01utWjCilXq6U+k+lVBHvdX/Dei0A9wDXKaXerZS6SSkVPsc+/wue5/w6rXXncQ4DVa11yXosA5wF3qeU+kWl1NA5tivHPXyO5x1XMM4AP/nIyh9a63rnYz51PIMofBSvSuAvgOfjGdsPdywzDCzZG9FaV2mvLBjwf3+BRwx5AzjtPz6+3gH78eH/CrzH3+ZrgS8Cn1dKHVBKJfFiw7evt34nWusa8Bk8z/MlwD+dY78/B3wc+DbwC8AP4HnP4L92rfWXgV8DbgK+Biwrpf5OKZXo2NxP4xnVf1lnV1Gg1nGMa3jv9Tzeez2vlPq6Uuq6jnVlvSiOJx3BrT4Ax9ailIoCLwT+q9b6fdbjnRfneWBwnXWT1kMZ//ergP9cZ3en13kMPMMdBwrgGSc/CfhF4N/xYsqnuEAD7PNPeLHgBusbRfCM7ne01q+VB5RSz+pcSGv9MeBjSqlB4OeBdwN54PesxX4L+F3gdqXUTVrrFeu5DJBWSnX5hle2ewz4L/4F6Ea8ErV/VUptt5brsbbheJLhPGBHBO923XhoSqkUnkdncxfwPKWUnXTrXOY4XqXBLq31d9f5WWF9FvHKrV4iD/he7M/iGeXfAX7fNl4XwO14ycQ/11rnzrFMjA7PFHhU9Yd1TEta6/cDX8eLr9vk8UIeGvj3jkqK43jx8Z3n2G5Da/1V4F3ACI8YXfBiwAAnznVcjisX5wE/xdFa55RSdwFvUkrlgTU8zy4H2Ebkr4DfBD6nlHo3Xkji94Cyv454rq8DPuEboC/ihTv24BnTF2uty+scQ0sp9UbgvUqp2/BCIi3gucBVeN73Hyilbl9v/XO8riaWQT8HtwN/q5R6A/Ad4Cf9fRqUUm8F+vDDD8B1wLNo935lnytKqefhGejPK6Ve4B/vnXiJxafj3wUopf4vvKTgJ/Fi8r14jSjf01rb3u73452LBy7kdTuuLJwH7AAvVnoaLx7613ie48ftBbTWM3ihiiG8kMBv4VU3BPC8P1nuk3gNFd+Hl5S6DS+mezeeMV4XP/zxErxyrU/hlaQdBJ6HF389CPyT3WBxEXg/8Jd43Xe34XmoL+1Y5i48b/d9eOGQ1+BVoPz1OV7HHJ4R3wXcppQK+8m3f8crYxPmgQW8ErgvAn8HPMSj7ypeAPzLBr1/xxWC0tqNJHJsDqXUj+B5e8/RWv9/W308lzN+wu9DwKgfXrmQdbrxjPSPaa2/cb7lHVcezgA7Lhil1DvwkmvzwAG8xoUV4DrnoT02SikFfA/4X1rrD13gOr8HvEBr/aOX8tgcW4eLATs2QgSvVG0bXnLsS8DvOuN7frTWWin1KrwL14WSA377Eh2S4zLAecAOh8OxRbgknMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFuEMsMPhcGwRzgA7HA7HFvGEGWCl1PuUUn/4RO3vUqGUKiql9mz1cTyVUEr9gVLqQiUcL3jZC9iWVkrtuxjbclw8lFIfVUr9sf/3jUqp40/Qfi/65+GiGGCl1BmlVF0pNdDx+D3+Qe/SWr9aa/1HF2N/W4nWOqm1ntjq47iSUUq9Qil1n1KqrJSaV0q9VynVc67ltdZ/orW+5UK2vZFlHZcW3y5UfKdlQSn1EX/C9UVDa/11rfV5JT79z9xlJ2p/MT3g08Avyz9KqWvwhh5uGuXhwiRPIvyZce8A/jvQjTcKfifeNOHwOss7zeorm5/SWieB64FnAG+0n3yqn9+Ladw+AfyK9f+vYs0Vs28b/P9/xveQ80qpU0qpF/iPf00p9Xal1DfxBj7uUUr9kFLqLqVUzv/9Q9Z2XqGUmlBKFZRSp/1x5vLcbyilHvKfe1Apdb3/+NP8/WSVUg8opX664zjfp5S63V/vDqXUTut5cxuilIoppf5SKTXpH9s3OqYGOyz8QZ1vBX5La/1v/jTgM3iz4HYCL1NKvUUp9c9KqVv9IaGv8B+71drOr/jv+YpS6g99T+vH/OfMskqpXf75+lWl1JRSall5AzhlOzcopb7tfw7mlFLvWe8i4Hj8+DMFvwhc7Z+T31RKnQROAiilXuTbg6xS6lvKG1qK/9x1Sqm7/e/jJ4Go9dyPKqWmrf/HlVK3KaWW/M/He5RST8Ob6feDvjee9ZeNKKXe6X82Fvzvfcza1n/3PxezSqlfv1RvzOP+Ac4AP4Y3fvtpeIMaz+J9qTTegMKPAn/sL38Dntr/8/AuAmPAQf+5rwFTwGG8iR3bgFXg5f7/v+z/3w8k8AZCHvDXHQEO+3//At6I9GfgjQTf5x9PCHgY+AMgDDwHb7qDbOOj/v834U2A+GvgG9Zr1cA+/++/9Y93zH/NPwRELsZ7+mT8wRsw2QSC6zz3MeAf8QZeNvCmKHfh3UW9BbjVX+4QUAR+xD9/7/SX/zH/eXvZXf75+qC/nWvxxtA/zX/+6XgeeNBf9iHg/1nvXLufTZ3vM9Z5Gceb7PxH/vt6O9606Ried7wIPNP/Hv2qv27EP8eTwO/4390X++dbbMmPAtP+3wG8sU/v9m1DFPgR/7lX2N9j/7G/Aj7rH0cK+Bzwp9ZndQG42t/WP1yKz8PFvr0XL/h5wDE8A7gerwQ+rLW+XWu9prWe0Vofs57/qNb6Ae2NFn8+cFJr/QmtdVNr/Y/+tn/KX3YN76oa01rPaa1lfPctwJ9rre/SHg9rrSfxvnBJ4M+01nWt9VeBz2OFT4B/1Vr/h/aGJ74B78o5br8APzTy68B/84+/pbX+lr7AgYtPUQaAZf+8djLnPw/wba31Z/zPRqVjuRcDn9Naf0NrXQfehPfFeCzeqrWuaK2/h/cFvRZAa31Ua33E/1ydwZuS/KzNvTTHOfiM73F+A7gD+BP/8T/VWmf88/sbwPu11t/xv0cfw7tQ/oD/EwL+Snt3TP+MN6l6PW4ARoH/rrUuaa2r+hzDTJVSyt/v7/jHUfCP7Zf8RV4CfERrfb/2plq/5fG8CefiYsdfPgH8B7CbjrHmHYwDX3iM589af4/iXQFtJoExrXVJKfWLwOuB/+2HLV7nG/Nx4NQ62x4Fzur2OWaTeF7so/avtS4qpTKynrXMAN4Vdr19ONZnGRhQSgXXMcIj/vPQ/j530nYetNZlpdTKefY7b/1dxrsAo5TaD7wL+H4gjvd9OHq+F+HYED+rtf6y/YBn+9rO8U7gV5VSv2U9FsY71xqY0b5b6tNpD4RxYPIcF/hOBvHO+VH/eMC7Uw74f4/S/lk41z4fFxfVA/Y9zNPATwK3PcaiZ4G9j7Up6+9ZvBNkswPfu9Za/7vW+nl4X+BjeLebj7WPWWBctSf3zPZ8jLervKxtn7+ezTJQPc/rcLTzbTzP5uftB5VSCeAngK/4Dz2WRzsHbLfWjeGFozbDe/E+M1dprdN4YSn12Ks4LhL2OT4LvF1r3WP9xP273TlgTFlWEu/7uh5ngR1q/cRe52dqGajghSxln93aSxji79e+6z3XPh8Xl6LC4JXAc3y3/Vz8b+DXlFLPVUp1KaXGlFIHz7HsF4D9SqmXKqWCvsd7CPi8UmqbUuqn/S9wDS822PLX+xDweqXU05XHPj+Z9h2gBPwPpVRIKfWjeOGMf7L2+ZNKqR/xEzJ/BHxHa93mlfke9IeBdymlRpVSAaXUDyqlIhf6Rj3V0Frn8JJwf6OUeoH//u8CPg1M491BnY9/Bn5KeYnZsL+9zRrNFF4Ooeh//l6zye04Hh8fBF6tlHqm/11NKKVeqJRK4V20m8Bv+9//n8cLNazHnXiG88/8bUSVUj/sP7cAbJckq//9/SDwbqXUEIBvh37cX/5TeAngQ0qpOPDmS/C6L74B1lqf0lp/9zzL3An8Gl6wPIcXG+r0cmXZFeBFwOuAFeB/AC/SWi/jHf/r8LzTDF787rX+ep8G3o4XPC8AnwH6/LjhT+N5XMvA3wG/0hGD/ge8NzyDl6i5mfV5PXAfXkwqg1de5crmHgOt9Z/jeZrvxDN+38HzXJ57IfFzP8b/W3gXzDm8c7uIdwHeKK8HXupv44PAJzexDcfjxLcXvwG8By/B/jBe0gz/+/rz/v+rwC9yjrtrrXULz5nah5fIn/aXB/gqXhJwXikloa7/6e/riPIqbr4MHPC39UW8JN1X/WW+enFebTtuLH0HSqmP4mVV33i+ZR1bjx8iyuKFEU5v8eE4HBvCeWuOKw6l1E8ppeJ+6OmdeHchZ7b2qByOjeMMsONK5Gfwwk6zwFXAL2l3K+e4AnEhCIfD4dginAfscDgcW4QzwI6nDMrT/3BKaU9BLtdzf1kYYGWJqTie2qgLkDbdokNzXGKeiuf+sjDADkcHF13a1HHF8JQ695eVAVaetOQ3lVLvVp4s3YTf8fQKpdRZpdSiUupXreVfqJT6T+VJWp5VSr2lY3uPJVvYpZT6PeVJYa4opT6llOp7gl+yY33OJ216zvPudz/d6p/TrPLkS7d17kApNaKUulcp9fpL+UIcG+Ypde4vKwPs80zgXrz+/n/A63h6Bl53y8uA96hHVPVLeCerB3gh8Bql1M8CKKUO4XW53YynE9FNu+DOb+NJHj4LT3hjFU9e0rH1HAHSytNtDuB1M91qPX/O8473he3G6+PvB16N1/Nv8G9l7wDeo7V+5yV7FY7N8JQ695ejAT6ttf6I31b4Sbw3821a65rW+ktAHc8Yo7X+mtb6Pl+28F48PVmREzyfbOH/DbxBaz3tt8C+BXixeoor9F9GnFPa9DznvYH35dvnSxse1Vrnre0ewtNwfrPW+gNPwOtwbJynzLm/HI3NgvV3BUBr3fmYyAk+E/gzPNHkMJ6A86f95c4nW7gT+BellC1L2cITgD+XjrHjieOc0qbnOe+fwLto/5Py5szdinehbfjP34zX2//Pl/j4HZvnKXPuL0cPeCP8A56i/bjWuhtv7IgoY51PtvAs8BMdEnhR7Y1OcWwx55E2Ped590W736q1PoQ3oeRFtMcU34InwvQP/i2u4zLjqXTur3QDnAIyWuuqUuoGPGUr4Xyyhe8D3q78eW9KqUGl1M88UQfuuCDOJW16zvOulHq2Uuoa/wuWx7stbVnrNvDGVSWATyg39PVy5Slx7rf8AB4nrwXeppQq4MV4PyVPXIBs4V/jXUm/5K9/BC8B6LhMeAxp03Oed2AY7+Kbx5vxdgftSRxb4nAI+PDl8EV0tPNUOfdPGS0IJ1vocDguN57UV34nW+hwOC5nntQGGCdb6HA4LmOeMiEIh8PhuNx4snvADofDcdniDLDD4XBsERvqhIvFYjqdTiNhi87whf14599ra2torVFK0dXVhVLqUevK861Wy/wty3dur9lsopQiEAgQDAYJBoPEYjHC4TDBYJBAIEAgEDDryLbsn80g2+pEKWWO0d6+vPbJyUkymcxmx6dvOUopF6t6fCxrrQe3+iA2izv/j5t1z/+GDHA6neYXfuEXWFtbo9VqUa/XjdFptVq0Wi2azSb1eh1oN5aNRgOlFNFolGg0SjAYpF6vs7bmdQKHQiFCoRBra2tks1nK5TLNZpNwOAzA2toajUbDrLO2tkY6naa7u5vu7m6SySQ7d+5keHiYgYEB+vr6SCQSFAoFqtWqMdCJRIL+/n4ikYi5EIiRt+nq6jLHJn/bFxbAGFm5YLRaXs13JBIhHA6jtaZer1OpVHjuc5+7kbfa8eRjcqsPwLGlrHv+N2SAtdY0Gg1jgGu1mjGG8iNGRxDDFggECIVCxGIxYrEYwaC367W1NcLhMNFolEgkQq1Wo1KpUK/XabVarK2t0Ww2qdVqNJtNms0mWmtisRjxeJxEIkE0GqXZbDI7O0uj0aBYLJLNZolGoywuLlIqlQiFQiSTSQYGBozxFiMMEA6HjUGV32tra22G2D4e++LRaDSMce7q6iIejxOJRMwFo1arPepuweFwODZkgNfW1ozX22q1qFarNBqNNu8xEAiwtraGUopQKGQMbavVMkZYfmQ9Mb6tVotsNkulUqHZbNLV1UUwGKTVatHV1UUgEDDrNJtNyuUykUgEgFwux8rKCj09PcYoB4NBpqenaTQahEIhUqkUQ0NDXH/99Rw+fJi+vj6zvhyr7CcSibC2tmZeT6PRoFKpUKlUyOfz5HI5isUitVqNYDBo9hmNRonH4wQCASqVinmPms3m4z9bDofjScWGPeBSqWS8vVarZeKwQjgcpquri1gsRjKZJBqN0mq1KJfLrK2tEQwGCYfDBAIBY7BiMU/wfmlpiXw+b4wvYIyiGEQx7uJRijHM5/OUy2XC4bAJXwSDQeLxOMlkkmazSaFQYHl5mWazSSAQYHx8nGQySblcJp/P02g0TKhiYGCAaDRKKBSi1WqRyWR44IEHzDFWq1Wq1Sq5XI5gMMj27dsZGxtjcHCQRCJBrVZjeXm57cfhcDhsNmyABYnnVqvVtmWUUgwODpJMJgmFQubxSCRCMBgkEokQiURQSlGtVgmHw6ytrVGr1ajValSrVXOrLx6vxJEB46ECJhwht/6BQMAY12AwSCgUIpFIEAqFaDQ8RbpGo8Hk5CTbtm0jHA5Tr9eZmJggl8uRyWSo1Woopejp6WHHjh0MDQ1RqVSYnp7m6NGjrKysmG3JMQQCAer1OplMxni/9Xqd1dVVisUizWbThCscDodD2LAe8HoVABIrFYOXTCZNkk282Xg8Tk9PD/F43CTbCoUCWmuq1aoxvrVazSTslFJtiTAxthJSCIfDJs4KnpEXQy1x5a6uLhO3luMol8vMz8+buPDExATVatUk/1qtFolEgmw2S3d3tzGuKysrxoOX1y2e8PLyMqurq6b6otVqUalUiMVi9Pf3E41GN32SHA7Hk5NNGWAprbITbxJWEG+zVCqZWG4qlaKvr4/e3l7i8ThKKer1uvmxKyUkwSUVCnY4QkrU5HnZlxjdUChErVYz3nA8HjdGUgxwNBqlXq+zsrJivN3FxUXC4bC5AEjlgsS3Jfa9trbG+Pg40WjUXDhyuRwLCwsmHtxsNo3h7+rqYmhoiH379nH33Xdf3DPncDiueB5XEq7RaFCr1QiFQsYwVyoVCoUClUqFrq4ukskkvb29DA4O0tPTQyAQoNFoGEMq9bzhcJhkMmmeF087EAiYbct+xQuWBJkYOzm2UChEPB43Xrgcq1wgAIrFIqurq8bjHh8fp6+vr63cTSlFqVQyxxiPx9m/fz+9vb2sra1RLBaZnZ2lUqmY5ezKiXQ6za5du7j22mv53Oc+d/HPnsPhuKLZcAxYPEExamJwwTPQpVKJarVKKpViYGCAgYEBdu/ezejoqPF85XZ/aWmprVYYIBaLtYUuxLA2m01TZyu3+RJ/lnKyrq4uSqUStVrNJOTs5xuNhjlW2afEcOV5u/EjFArR3d1NrVYjn89z+vRpTp8+TaVSobu7m1gsxujoKJlMhkwmQ7FYNBclqYyQ6giHw+HoZMMhCLsO2I6Baq1N+dbw8DAjIyP09/eb+OfS0hJKKWq1GsVikfn5eTKZDIAJY4BnLKWu1zaadiddNBpl27ZtJBIJE+4olUqsra3R29trknB2lYaEJYrFoilvk/riarVKuVw22xcPW4xzsVikWCwSDAaZnZ1lbm6OZDJJX18fg4ODxGIxU0on70MikWDbtm0mIbnZzjuHw/HkZcMesBhfCSFItUIsFqOnp4eBgQG2b99OKpUyMdypqSlThlav1ymXy6Z0zC43k5pcMZqSyCqXy+YYJLY7OjrK8PAwWmuy2SwTExNks1mSyaTZT6PRMHFcCT0opSgUCqZdOR6Pm/hzMBg0r1GMtnT32YnBZrNpPP94PE6r1SISiRCLxejq6qKnp4fdu3dz9dVXs2PHDlKp1MU6Xw6H40nEhg2w3XJsVzgMDAywbds2xsbG2LZtm6kcWFhYYG5ujkwmY9aRGGu1WjVxWalaSCQSbXHmUqlk/g8EAoTDYVNZMDIyQjAYJJ1Os7Ky0mYQpYJCjLeUqonxjMVipFIpksmkaQKxS8XEi5YEnnjHUuEh3j54Fw+70mF0dJTDhw9z1VVX0dfXRzwev1jny+FwPInYsAGu1WrGAGutTTigr6+PVCpFtVrlwQcfZH5+npWVFTKZDKurq5RKpUfpLcAjdb0SFhBPVZJvUnNbr9fp7e01Rh68Jgwxkl1dXaaWWDQfQqGQiRU3m01KpRKZTIZUKsXo6Cjj4+MMDAxQqVQ4cuQI+Xy+LYknMWuJTweDQQYGBtixY0dbXLdcLrfdBUhDhnQBOhwOx3psyEK0Wi2KxaLxgsEr/crn86bhoFAoUCwWKZVKJgQgVQ/iVUojhYQKQqEQkUjENFKIUY5Go4yNjdFsNpmZmWFkZIRrrrmGHTt2AJDNZo02QyKRoK+vz9TqptNphoaG2L59O7lcjmq1asrD1tbWTAhBwgUrKyvcf//9JhYMnmHNZDIm1NLV1UUul0NrTTweNzXNEoLo6emhp6eHVCplSuLEq3ZaEA6Ho5MNl6EVi8U2ZTBpimg2m1SrVSqViikPk9t6qSqQBJeECIA2g1ypVKjVagwMDDA+Ps7evXs5ePAgi4uLHDlyhF27dnHgwAF27Nhhkm+2cRwZGWFhYYFCoUCpVGJmZoZQKES5XKZcLhtRHAmFSO1yoVBgaWnJJBMldFEsFtsqLaLRqEkiJpNJU+UgNcOSoBT1NfH4nfF1OBzrseEQRKVSMX/L/5Iwk5rbQCDQpo0rTRXBYLCtphceUSETjYfBwUGuvvpqDh06xMGDB9m1axf33HMP6XSa/v5+tm/fzvbt29saOWSfAwMDjIyMsLq6ytLSEhMTE5TLZeOBB4NBotGoSaQ1Gg2y2SzZbJbFxcW22LMYYVFrSyQS9Pb2mm4+Mb6xWMx4/rJ9wDRrOBwOx7nYsAdcrVbbxMal80yMje39dpaAScOGXUlha+3G43EOHTrEjTfeyNVXX82uXbuIx+NMTEyQTqdN2Vd/f7+RgLS3I00V0p0WCASYmZkBMDHhVCpFMBikUCgYr1UaKeRYJDQCGDGf3t5eRkZGGBkZYXBwkL6+Pnp6eohEIqYjTiopZD27fdoZY4fD0cmGs0S2AI4YKmmCEGMrt97iFQeDQZLJJPDIRIlIJGKaNsAzWDt37uRFL3oRN9xwg0l0zc3NEQ6H2bNnD+Pj48boSZJO9id1vc1mk97eXvr7+9m2bRunT59mZWXFKLGJZ7q0tEQ2m6VYLFKv1038WTzjRqNBLBYzXq9dYjc2NmaqJ4LBILVajbm5Obq6uiiXy+zevdsowUnIwxlgh8PRyYY9YDtJJd6sxHHtCROi2yDGR7xeMYKpVMpUCqytrRGLxdi7dy9XX301qVTK1AtPTU1Rr9e56aabGBoaoru721RHdHrXYojtx9LpNIVCoa0uuFgsmlpiOX65MIg33Gg0jLavNFrEYjH6+voYGBgw4RTx+EWistVqGQU1Mb7lcrlNpN7hcDhgEx6whBEkDGEbWMDEUe05cFLaJa3Jo6OjXHXVVYyOjhKJRFhZWWFhYYFSqcRDDz1ktHml4mLnzp2mzlZafRuNhkmiiZylLQ4vseVEIkFPT09b84iEH+SYJWYtIQ3xhO3XKlUZIrMp1ReNRsPUCksislAoUC6XKZVKrK6uMjs7a1qgHQ6HQ9iwAZZbfvF+7Rhnp1i6tA2nUikOHTrEvn372LlzJ2NjYyac0NXVxerqKgsLC8zPz5NKpYwhDIVC9PT0kE6nTQmZGEcRzQHM/xLusMMgXV1dbeOGpGRManvt8UN2bFq64WwNCgk5SGxXDH8+nzfhlGg0SqVSIZvNsrKywuzsLFNTUyZ56XA4HMKm5Cjlxx5ECTxq2rF0iw0ODnL99ddzww03sGvXLgYHB9sMrTRYDA8Pm8kXiUTCqKnZouz20E/RchDNCDHAneOFxIOVTjo5djHUYmTFo7UnNMv25fXYr7HZbJLL5Zifn2dpaclcEDKZDK1Wi4mJCaanp1lcXGwTcXc4HA7YhAG2hXPs8fHynMSD5blAIEB/fz8HDhxg//79DA0NmYkYUr2QSqVIpVLEYjETGrA9zEAgQKlUMt6p1NnamsQSgrDnzonWg8SG7Qkb0WjUhDAEEd+xwyeCnWSU+udCocCZM2e45557OHnyJM1mk56eHhMeOXXqlKmbdmI8j5+NvIfrTa9e7zmHYyt5XFUQ8kG2f4uxsT3PaDRquuAkCWe3DtsTLUKhkBlkKdsVo1etVimVShQKBWq1mmnEkHCF3dJsi7dHIhFTuytdapJgEwUz8YjtL6scl3jPXV1dplljdXWVM2fO8O1vf5vjx48bg726uko+nzeGX8rf5ubmHt+ZeooguhxS222L8tuxeqDtb2ifmnIuI2vfvYnzYE9ecTieSDYVA7Y/5HZNMGC0HOxhmhLHjcVixusUPeFCoWC0GkS1zC5jk1pjkY3M5XJMTk5y+vRpM3hTDK7dCFGr1UwoQMTeRaehu7ubeDxuvGAxyPKll5/OL7pUgczNzTE1NcXJkyd56KGHKJVKpFIpE4eWmHR3d/ejvGzHYyO11DJXz54BCJBKpdo+J2KgFxYWzP9yruxpKoLUeneGkuzPtcPxRLFptRg7FiwfehlFL96ETLro6+szVQz2mPdqtdqmGyHz1uyQhjRK5PN5k9ian5+nXq8Ti8VMOEOeF2Ncr9dZXl42HmipVDL7CofD9Pb20t3dTXd3twl/yBdbtmEP05TE3NmzZ3nggQeYnJxkbm6ORqNhxNmr1aoxGqLuFg6H3Zd6g0hs3n7ftNYkEgme+cxn8qxnPcucd4Bqtcqb3/zmthb3x3rPbaNst8i783R5MzY2xqte9apNr99qtXj729/elrfaajZsgB/r1q6zCUOGdA4MDNDf328mVIj3K63E4uHalQqyrbW1NRYWFszQSxFnHx0dpa+vr0305uzZs2Zd8DybeDxujLo0TFQqFXp6ehgaGmLbtm0MDQ2Z6giphJAEodQIS4Lu+PHjRu2tVCoRj8dJp9MmDq21Nx9PmkUe6z1zPBo7BCRe6sGDB0kmk/T39/PCF76Ql7/85aalXEJTX/ziFx81oXu9O7Suri6OHz/epmlyIUbbsXUcPnyYRCLB4cOHedOb3rTp7TQaDb7yla/QaDSYnp5mdnb2Ih7l5tiUAe78oNp1wXYSLR6PMzQ0xOjoKOl02oQe5HkZkikGL5vNGiOrlCIWixEMBjl16hSLi4sAdHd3G7HzeDxuxhtFo1GWl5fJZrNEIhGSySSpVIpdu3YRiURM/e/i4iLlcpmlpSUTT15bWyMajRrvXaZh2BrC+Xyeqakpjh49ao4vkUiYLr98Pm9mx6XTaRPLtt83x2MjFyyp5xZt5w9/+MNcf/31AEb4yE6qRqNRvvSlL7UNb7XjxXZuoquri2c/+9ncddddpqrG3reLBV9ehMNhPv7xj5vz/3gIhUJ84xvfAOBtb3sbb3/72wG2tElqU4LsdnOCeKm2ARbju2PHDq699lr27t1r9HUlMVapVIzhk9jqysoKDz/8MNlsFq218T7r9brR4d21axd79uyhv7/fJMVyuZwRWC8Wi6b6ob+/n3Q6bRJ+5XKZQqFAoVBgfn6eubk5stksZ86cMTXJ8oW0a5ozmQxTU1Pcf//9pqRMkodKKc6cOWNi0PF43MSD5TXatdGOc2OHsaS1/B3veAfj4+PGiIZCIWKxWFu4wV4XMPFfW+jJjue/+93v5hOf+ASf/vSnjRck591x+RAOh1lZWSGRSFz0bb/hDW/g93//96nVavT19W1Zmeim6oDtRJXU4MpzQjKZZNu2bUb0HB4ZhFmr1ahUKrRaLWq1GktLS0xOTnLvvfcyPT3dJuQTCATYtWsX+/fvZ2xsjKGhIdLpdNuctXq9Tk9Pj5HFBC8J2NPTY0YUiQGWxhCJR8/MzJDNZjlx4gR79uwxYj1CNptlamqKEydOcOzYMfM6petNLkbd3d3Gi5ZSOVsDwhngC0M+I4lEghtvvJEbbrjBfAHtJiBB3n87ZmxXwsj/sm2lFFdddRVPf/rTOX36NA899BAnT550SbjLjMOHD/Pxj3+cRCJxSUo4OxPtW8WGDbBtfO3khdyui1Hu7u42MdZEItGWmRZNBhlZNDs7y+TkJKdOnWJpaQnAVC7s3LnTGHFJltnC6mKopWtOqjDk1jQcDrcpp4GnjCZZ9kqlwurqKvPz8wwODhrDLCOTlpaWePjhhzlz5oz5Atsi8xLnjkQiJu7bmTxyXBh2BcPAwAC33HILe/bsaUvswiP15sJ6usvrGWn5OxKJ8H3f933U63WSySSTk5NtM/+cId5anv3sZ3PzzTdflLDD+QgEArzpTW/ive9975bEhDdkgMXTsBsS7JgueIZTqgxEOlKMonSxSfXD5OQkDz/8MPPz8ywsLLC0tESxWAQwnqq0LScSCcLhsCk7k2YIMfz2OnYbsq33IEnAcDhsxt0XCgUmJyfJZDLGKwcvlLK6usrZs2eZnp42Az+l5Vi+sDKjzva4JBwhMWF5zHHh9Pb28rM/+7PGI5bPlzTerMeFvsdaa/bu3WuEmr7zne8wPT1tQkp2ZYTjieXw4cPcfPPNvPKVr3xC9hcIBHjjG9/IZz7zmcvfAAOPMrpSQ2mXpInS2LZt20in06YyQcYVZTIZzpw5w3e/+11Onjxpmhvi8bhJ1CWTSZPAk3ZkMWwyrdhGJnPYhlZrTzBe1pVb03g8bsbWl8tlBgcHTXVEtVo1Hlc+n2d5eRmAdDpttifHKw0eMpxTQidS+2sneRznR+4o7A5H8Ygl6SYC+XL+15sz2Int0cpnUZKo11xzDS972cv40Ic+5JplLgM+9rGP8fSnP32rD+MJY0MGWBor7PIdux5Tlunu7mZsbIx0Om1kJbXW5PN5VldXmZmZ4Vvf+hbf+973WFlZIRKJkEqlTLNGNBolnU4zPDxs9HYDgYBRSINHBM9t5bJqtcrq6iqRSMQ0WEh9r8Sby+WyqfdNpVIMDQ2xe/duTp48aUISEkrIZDLMzs6acIY0jQQCATOSSLx7+4IgZWgSJ7briR2PjdxZyPgre7QTYGq8RanuQlmvwzEej3PDDTdwww038OUvf5mVlRUnG+p4QtlwFURnK7IdlpBSnsHBQUZHR0mlUoBXOrS8vMzy8jJTU1NMTExw8uRJKpWKCSsAxrDJwMtwOGzG/YgRs2uIxfhprUkmk6YeWIyhPW/OVnArFAomjCLTLkQcSIyzNH/Y3VLFYtGUx4ngumDHL6Uhw86suhDE+bETaSdOnOAFL3gB4F3cXvrSl/Lyl7+c3t5egEd1s50LuylIzpF8buRxCWe5u5Wt52Uvexmve93ruOWWW7b6UJ4QNmyAO4VlJM5phwd6e3vNmHqZErG4uMjZs2c5fvw4ExMTRi9BPFQJHUgcVwxxs9mkUqmYfYgBtj3VYDBIJBIxX+BOkXY5bnkNkkQT0R7xmMVgS01yNps1+6xUKlQqFRPCkBInu7VVQjPiRZ1LY8KxPlprc8Esl8scPXrUXOTD4TBnz54llUqhlOKWW25hZGSkLQewHnb9r5wDu7VZEsNSi+7YWo4dO8att97K2bNnCQQCvOENb3hCWvlf/epXc+utt3LHHXdc8n3ZbNgA216veMQSr5MviqibSbdSqVRiaWmJqakppqammJubIxKJMDQ0ZOpvRX9XBHPS6bSRpOzU/pW/xXBGIhHTFCGeuK0RYV8k7GOGR8rq7OWljTmXy5nQh0xsTiaTj0q4CXZHlRhj2b4zwOdHjKlcMO0475EjRzhy5Ij5jF177bX80A/9ED09PcZwd1afPNY5spNstgSpM8Jbzx133MEdd9xBKBTiOc95jsnpJJNJDh06dEn2+QM/8AMcOXLk8jbA0P4BlmoEO/6ZSqXo7u429cEStxUPuFAoEI1GjaGV0jEpwBfRnFQq1RbnlfHzYjwlNCEGuFarEYvFjFdtf8HsWlGgzQDbGW+pUW42m6yurlIqlcwtr7Qli6dr6xWIkQZMOEXaku0SKMf5WS8GayfhRHL0Xe96F7lcjhe/+MU0m02T7JXzLEJNdoLYRoyt7fnaDoarhNh6Go0GN954o/n/+7//+/nmN78JsOEcwPl4xStewdGjRy/a9i6UDZehdSbcbBlIue0PBoOUSiVjKHO5HDMzM1SrVdLpNIODg6bVNJFImEoCCT/09PSQSCSIRqMEg0Hy+Tz5fN54yWL4pKFDLgTg3V7WajWi0aiJ0Ur1g63tYNcll8tlM4JeEm3z8/N0dXVRKpXMfDeJ+9ots4AJO9hfVjuL75Jwjw8JA8n5K5fL3HnnnUxMTPBv//ZvfOQjHzFGWi7WnSpqNjKEVcSf7M+xa565fDl69KgZ7nvkyJEnpE74UnP+Gh4LafEVWUm7M8lWOBOjUy6XTbPF3Nwc9XqdaDRKd3e36Wbr7u42gy57e3tN6EE85L6+PoaGhujv7zeqY/Donn2phhCdYDGknUlCuUBIfLher5PNZo3HVCwWmZmZoVAo0N/fbxTUxADLa5d9SsINaAs32HXS0rTh2BzSli5awVJGmMvl+OY3v8krXvGKtti7xPPPdQfSGWoQCVE7nuyM7+WHnb+5+eab+dCHPrTVh/S42VQjhnh3YlhsERS7XlPqbDOZDNlsFsCMahftXtFOkG6yWCzW9iOlXnZ1gcxXE8NvtzfbM9xkG4LIRMrkDdEYLhQKhEIhGo0G+XyeQqFgvCL5ckqbsdSg2reuEosWj0uSdnbtqePiIZ8tpRTZbJYjR45w5513snfvXhP+gvawkY38X61WWV5e5uTJk6a80c4VOC5fjh07dlmomT1eNtWIIQbYrsGV2zmpTJAZa/aU4GAwaMqzJEQgcVvxeOPxuNleNBo1gzBFAUu61cQQ2vKRQFs8VkrL7NieTDYuFAqUSiUzvTgWixlvt9lsGsGXTq/KLjcTj8meliytyoCZ1uF4/NhJU4mvS1gpk8lw22238bKXvYxYLGbOgx1qsnMXkrArl8scO3aML3zhC20lh44rg5mZGR588MFLlph7ItiQAZbbPPESbI9PyrlEZ0G81XK5bMrI7DZSkYuUkEYymWwrXbNL28RwwiPZazGOjUaDcrkMYBI0MkhTEmqynhhL+fLV63WKxSKNRoNUKmX0hCUmPTExYWKLdtOHaBhLN5xM1JBSOLnodM6Vc2wOMZhSzSKfIYmtV6tV3vOe93DDDTcwMjJCKpVqE1vp1P2Vz1e5XOZb3/oWH/jAB9zQ1CuQD3zgA9x9991885vfNGHBzdCZv3ki2bAB7hyvLl8I8UalckHadldWVpiZmSGXyxGNRk2nk10BIQkRqYLoLEWSUUHiCUshvVwARF9Ca29qglRBSCjAjlmL516tVslkMiwtLdFqtRgYGDAGWIx0JpMx5XQi7GOPrxdjLDKXQqvVolgstjVkuCTc5rHvItZLdNr1vXb4QT434gnLnZncMa2trZmZgPbn2HHlcPToUfr7+8lkMm0NNhdKvV6nr6/POHFPNBuOAUt8184Ud5Z5yQe+VqtRKBRYXV2lVqu1GTA7QWUXwovnYpeJSWmXXVEg+5JYdLlcNvFdWa5QKJiEjV2pIUI7CwsLxsg++OCDAOYCsLi4SCQSIZ1Om3ZrSTrKtiTmnM/nzXQP8ZLFG7dfr+PSIJ+3YrFoyhwl4ZrNZs3dWalUIhKJsLq6ym233canPvUpTp06ZaZs2/FfFwe+MtBaP+728SvGA4ZH6lzhkcoDoM1j7Sy7kgzzuZ6HR0IEdqxOPGHb+MlFQJJedrhCjGC1WjVeaSwWM0ZXuteWlpaYnZ2lVCqZxFo2myUejxvtYIkLi+crX0jpxCoWi3R1dbG6ukqxWGxrSLEFX85Vh+q4eMiF7rOf/SwLCwtcd911/PAP/7Bp2pAQkhjZv//7v+fzn/88//mf/0mpVGrzkjuTcM4IX/60Wi3e+ta38trXvpbR0dELXm96epr3ve99W3rXsyk9YFu82taGsJHGCknKdXaJAcablC40e7lOj9ouJ7O1fiXxJxKRpVLJLCuJPInVShx3cnLS6A6n0+m20UHlcplisUi9Xqe3t9eI+sixpFIpY/xFaEfCKlI5Idiqcc4AXxrsxosvfOELzM/Ps7a2xk033YRSymhRiwbEsWPH+MQnPsGDDz5okqiyvvN8r0xk2ObP/dzPXbABnp6e5vbbbzdjibaKDYcgJIbaGVez62wlFNBqtUyjRS6XM56IGHCJ+Up9rXginX37tpYDYKoOZCyQeL25XM48JnW9MjdOytey2Sy5XI5wOGwmddx111309fWRy+VYWloim83S3d1twhGSaJOROKKsJombZDJplpHjrlarxkDDhckmOjaOXNCl+qTZbBIIBIjFYua9l89EIBDgNa95DZOTk2ZdyRVIfkCcA2eErzyk6uh82hGNRoO/+7u/40//9E+foCM7NxtOwtnlQOIBy/9ihEUnd21tzYjqSDJK6m+l88z2fuU5u+TL9k5sj0UmUEiCTDzSQqFg4rq1Wo1MJmMaLFZXV8nn8+zZs4fe3l6y2Sxnz55lZWXFSFlWq1WjZyHeu61HIfFsqZwYGRmhr6+PYrHIysoKmUzGyG9K80AwGHRas5eQzrCBNAR1dXVRLBa59dZb+eQnPwnA/fff31bxYJdVOqN7ZXPTTTfx5je/mTe+8Y3nXe7OO+98go7qsdlUK7IYRzubDN6tQKFQaLsSRSIRMy/N7lJbXV0lm822GTqp9RVPc73JG7YkpYQcstmsaX22dX9luKeMN+rp6WH79u309PSwtLTEiRMnmJqaMloS0tYssV+JEctztVqNSCTCzp072bZtGz09PcbwnzhxwgjOh8NhU14n5WkTExOX5AQ+1bFDW+DdeczOzvIf//EfphLnyJEjfO973wMe6XqzQ0PO8D45aDabvPe97+Xhhx/mox/9qHn8/e9/Px/84AfN/w899NBlU5W04RgwPFIUb4+gt6cdi7aCUt50DGkzXl1dNbW3q6urLC0tmbphMehijCU2LPuzKwzsRFk+nzfj7CUZJt64rS3R29trRH4WFhY4duyYGXUPsLq6SqPRMFrE0l1Xq9UArxFjZGSEkZERtm/fTl9fH5FIhHw+b0YadXV1MTAwYFTcpClAvHbHpUOM6MLCAt/+9rdZWloiGAxSrVZ56KGHKJVKbW3zLsn25GR2dpbbb7+dN7/5zeaxr33ta1sitHMhbLoTzg4/yGMSQhBPUOK/27ZtY2RkhHK5bKQd8/k8S0tLpoNMevftxJp4N3JLWalUjCpasVgkn8+Ty+XIZrNkMhmjNSHtzX19fYyNjZnBoNJJd/bsWSYmJlBKkUwmaTQaZLNZk6iT4n7AxLGHh4c5dOgQe/bsMRrG4n2fPn2aUqlk9plIJIxgvMTMHZcerbUJA917771EIhEjNWmHKZzRfXIzOzvL2972tq0+jAtiw3rAwKOqFezAt2jpDg0NmSaG0dFRcrkcuVyO5eVlI9QjhlMaJSSpZ7cga60plUpm/WKxyNramtEYlrhuPp8nFAoxMDDAtm3b6O/vp6enh4GBAeLxOOBVOJw8eZK7777bJMxKpRJzc3PG+xXDHgwGOXjwIHv37mV0dJShoSHj3RaLRZaWlpienua+++6jWCzS39/P4OAgPT09be2yTgnt0tJpTO1yM/siKA0YDsflxIZjwFJZIB1E1WqVfD5v4rKi/Xvw4EFisRg9PT309fW11c4uLy9TrVYplUqsrKyY+G88HmdwcNA0Voh3LII+y8vLJslVLpdNHFm0e0VTYnBw0CTHenp6AJifn+fUqVPcf//99PT0UK1WzboSK9yxYwc7d+5k+/btjI+PMzw8zODgoJl6LJ735OQkDz74IBMTE2SzWYaGhhgaGiIcDpsEjyQGRbfChSAuHXYeQgxyKBQyYSR5zJ0Dx+XGhkMQYmjF4xXJx1arRbVapdVqsbKyYrzggYEBEz/dtWsX5XLZGO18Pm+Mby6XIxKJsLy8bETd0+m0mXggspYyul5iyfl83njF/f39jIyM0N/fb8YGVatV5ubmmJiY4MyZM2bAZ71eJxKJMD4+TjqdJp1Os3v3bgYHB0282BbYkVvXubk5jh07xtzcHGtra4yPj5uYr3TUSKeeePK2Uprj4mOXLiql2qam2FrRdsLOhSEclwObSsKJloJ4wJ3KU8VikeXlZbLZLP39/Wb22tDQEIVCgUajwczMDPV6nZWVFSqViokXl8vltokZfX19BAIBcrmckbUUAyxi6c1mk1Qqxfj4OCMjI3R3d5uQxtTUFNPT08zPz5sqh2w2SzAYZHh42Fwkent7GRwcNELwEg+2tY4rlQonT55kYWGBZrNpBIUk2SPxRpmaIXKI4kE7Lg22Me1Uv+t83lU9OC4nNlWGJsZFEkzi3Undbq1WY3l5mYWFBSO4EwwG6evrM8sHAgHm5uaMKpndLCH1s/F4nGw2SyAQMOI2Uv1QKpWM2lk4HGZoaIidO3fS399PNBo1F4KTJ0+yuLjYllQrl8uMjY2xb98+UxMs2sF2C7HEDGWd2dlZk3ATYXlJ9Nht2fYwUJlz5wzwpWU9r9buunQ4Lkc2lYQTbG1VaRNWSlGtVllcXDQlZgCjo6Pmtn5gYIDBwUGOHz9u5sTV63WTSJPmDCkxA9pkMCuVCrlcDvDE0Ht7e9m7dy+7d+82ugC1Wo3JyUlOnDhhytvEI04mk1xzzTUcOHCA0dFRksmkEQ+Si4u0FYu8ZCaT4e677zZiL1LSZndfAaZJRDx4+dmMUpPD4Xhys6mhnHa4ATCz2iTU0Gq1WFxcNMI7kUiEnp4eUyIWi8VIp9OMjIwwNTXFxMQEMzMz5PN5wIsrSwJLxtqLDKbM/Wo2mwwODjI8PMz27dvZvXu3aZ4olUrMzs7y9a9/HcA8Xi6XqdVqPP/5z+eaa66hv7/fhA+AtguJxH7F+J4+fZp77rmH/fv309/fb2KNckySaJMk5eDgoBmhFI1GXQLI4XA8ik3VAYvxlRZhUSeTCRfS+lssFpmdnaWnp4eRkRETXw2Hw2YEkQjmpFIpJiYmTIxYQhydwxXF2+zp6WF0dJTx8XHT3QaY9uKzZ8+aduGVlRXT1Xbttdeyb98+0ul02yjzzokJAJVKxSTwJicn27xrwGgQ2BoXEsIQTQxJArlSNIfD0cmGQxCdYiWdEpEyZFM606rVKgsLC8zMzJBOp42XHAqFjFKVNHZIQ4RoKUj8NJFI0N3dbTztYDBIIpFgbGyM4eFh+vr6CIfDFAoF5ufnmZ2dZXl52cx0K5fLhEIhhoeHOXDgAP39/Y/SNRYP1RaDl2Ofnp5mZWWF7u5uUyIny4vxlZpfW0JTQjIu6+5wONZjU2Vo8IgnbCfgRIVqeHiYaDTK0tKSEcc5ffq0kXcUz1Bu13t6esxkA7uyAR5p+rBv4UUsR0YYifDPwsICs7OzLC0tUalUSCaTJoY8MDDAvn372L17N4lEwoQQZL+yH3vkTa1WM80ipVLJ1ChLiESMr2hUiLhQp7frhF4cDsd6bFoLwjYyYrykXAs8nV2JAWezWU6ePGlu+8VrTiQSrK2tEQ6H6evro6+vz6ifidiO7U3acoGS2JLlc7mciSVXq1Uj5lOpVBgcHOSqq67iaU97mrk42NoSMg5JQgq2DrE9gUOE2eGRkAU8WgbPLoOSagpngB0ORyebigHbEymkOkGU0AqFghkDI7WzUrXQ1dVFPp8nk8mwa9cuuru7Aa9sSzznZDJpRhTZhkuqDcSwyRiSVqtFqVTivvvu47vf/a4ZcQ+Qy+Xo7e3luuuu46qrrmJsbIxQKGQaRsS4SgOFxHDlQiKvR2tthHWktbWz9tSW5UwkEqbio9lsmknLDofDYbOpEIRtfOR/8TjBM3x2EXxXVxeNRsNMK5BR8ENDQyQSCdLptOnft1XQACO0LV6mdNxFo1EymQyzs7NMTExw7Ngxc/tfKpWMUtv111/PoUOH6O3tNZNwpbpCEIMvr0EuKNlslsXFRdMm3dnNZmtiSNItHo+TTqeN/oQ0jLh6VIfD0cmmhnLCI/339shwuVW3RxYJWnvD81ZXVwGMoRwcHAQwEy5qtRrRaLTNoANtHmY4HKZcLjM3N8eJEyeYmJggn88TjUYpl8smFj00NMTevXvp6+sjFAqZRJ/EamV7cjx2klGOVWLIsVjMePuAiWEDRsdYOvik8UJCHG4kkcPhWI8NG+BEItHWCSeiJ3brra3jKwZNYriVSsXc9stkiWAwSDqdNtUFUlcrtcCdxqvVarG8vMypU6eYmJhgcXHRaEo0m802+cjR0VGi0WjbfLbOOW12pYLEniuVCplMhkqlYtqaJflmK24JoVDITOeIRCLAI551ZxLR4XA4YIMGOBAIMDo6alpzZc6bbdTE6NqjfCSmak+0qFarpla41WoRjUbp7e1Fa22UxOz4rHjatVqN+fl57r77bh566CEKhYJpmsjn84yNjXHVVVdx4MAB9u3bZ5Jg63m4toCLGFQpP5NWaknSSbu01BvbFyDxymWAp2xDjK/oSjgcDofNhmPA0mghXqUYMnuKhWgqiMGrVCrGANshDKn7zWaz5PN5MzjRbmqQcIMk8mZmZjh69CgnTpwAvGoI8OLO+/fv5wd/8AcZGRkhnU4bNTTpogsEAqZWVwynlKPZDR/1ep3p6WmmpqbM65C4s1RCyAVCQiPyXsisO1FBk+25JJzD4ehkw0M5Raxckm920kwSbp0ese35itconXPd3d2kUikzHVlmxAHG65QZctPT0zz88MPce++9FAoFUqkUrVaLWCzGtddeyzOe8QyGhoaM7oJMz5CyM7kQ2IplUgecTqep1Wqsra2Zho7V1VUjChQKhYzEpbwW8Y5lX4CpehCPWC40LgnncDg62bQBFsMiSBxVPEF75pY9/NBuy1VKEYvF6O7uNoM7xQsVMe3V1VXuu+8+jh8/zsrKitERrlQqDAwMMDw8zMjICAcPHmRkZMQ0R0h5moQu7NDDmTNnyOVyJh4di8XYsWOHqV1eXV0lk8mY0jo73mvPp5PXItUXUqkh+hX2qHNngB0ORycbDkHIsE14xOOVv+XH9ixtWUZBDHI4HDajfGR0kCTT6vW60XU4evQo999/P/V63Xic8Xic4eHhtrFBkvQSw1ipVNoScLVajZWVFU6cOGH0IcQAl0olRkZG0FqbcEgkEiGTyZgLjWhA2CEFiR/b3j7Q5vl3Nq44HA4HbEILQm7hxYjaWgiyjJ2Ig0fqZWU9kWzctWsXhw4dYv/+/YyNjRnx9Xw+z8zMDBMTExw/fpxSqcSePXtMPLdWq3H48GGe8YxnMDo6SiKRMEZSEnVSXSFeaKFQYHp6mgceeIBcLmeU1Gq1GsVikbNnz5qR8sFgkIGBARqNhjHAjUbDlLrZ3XmdrdhSt+xmwTkcjvOxKTEeO4xgJ+A6479SZWCXqIk05e7du3nWs57FgQMHGBwcNMm0xcVF7rnnHk6dOsX8/LypmGg2m4RCIUZGRrj22mu57rrriEajNJtN6vU64XCYSqViDKF45rlcjpMnTzI7O0smk6FarRKLxahUKma5RCJhBoaK8I80UkjSzU4QSvxaEm22CI/d+SZqb/I+OBwOh82mWpEBU7IlBlcMjG2IxQhKMiyZTDI0NMSePXtMh5qEHprNJlNTUxw9epTp6WlKpZLxeNfW1ti+fbsZmrlr1y5isZiJw4pout1oIZ13x44dY2VlhUajYeqYA4GAafqQDjiJ4YoXm8vlmJ+fJxwOE4vFTE2yXAjkb/Hs5T2Q7XRqQDgtCIfD0cmGGzHsv+3ElPxvP2bX3yaTSXbs2MHu3bvZt28fe/fuNQM7C4UCKysrnD59mjNnzhhh9kAgQDweZ2BggKc97Wls377dCJ13ymJKvLlQKJDL5VhdXWVmZoapqSlTixuJRIyRtA2neOgiAiQaF/akC3lOtmXHdm1xdtmmPYjTqaE5HI712NREDPvv9cTG7bCDUopoNMrQ0JBpjti5cyeDg4Nm5Pzs7KwZnlksFtFam/KvVCrFgQMH2L9/P93d3aZ+V0q77J9Go8HS0hJnz55lbm6OTCZDvV6np6fHlJDJHDk7TGGXyYlHHY/H2/6v1+vGQ+4cgS7bsH9LR6BLwDkcjnOxYQ9YMv624e0sLZMQQDgcJp1OMzw8zK5du7j66qvNbLhgMMjCwgJzc3NMTk4yMzPD6uqqaaBIJpP09fVx8OBBDh482FbqJYM8peyrVquZGO7Zs2eZmZkxguzj4+N0d3cbo20nz2wxHXkNoVCIgYEBtm3bRqvVYmVlhVwuRz6fp1arEYlE2mLesq4dGxcvWcIWdojG4XA4BLWRW2Ol1BIweekO50nNTq314FYfxGZx5/5x487/U5t1z/+GDLDD4XA4Lh5OIcbhcDi2CGeAHQ6HY4twBtjhcDi2CGeAHQ6HY4twBtjhcDi2CGeAHQ6HY4twBtjhcDi2CGeAHQ6HY4twBtjhcDi2iP8fayTXMUdRac0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VisualizeImageAndMask(image = test_images[0], mask = test_masks[0], prediction_img = op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae2fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
